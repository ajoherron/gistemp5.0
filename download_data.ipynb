{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHCN Land Data\n",
    "file_url = 'https://data.giss.nasa.gov/pub/gistemp/ghcnm.tavg.qcf.dat'\n",
    "\n",
    "try:\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(file_url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Get the content of the response\n",
    "        file_data = response.content.decode(\"utf-8\")\n",
    "\n",
    "        # Create a list to store formatted data\n",
    "        formatted_data = []\n",
    "\n",
    "        # Loop through file data\n",
    "        for line in file_data.split('\\n'):\n",
    "            \n",
    "            # Check if line is not empty\n",
    "            if line.strip():\n",
    "                \n",
    "                # Extract relevant data\n",
    "                # (Using code from GHCNV4Reader())\n",
    "                station_id = line[:11]\n",
    "                year = int(line[11:15])\n",
    "                values = [int(line[i:i+5]) for i in range(19, 115, 8)]\n",
    "                \n",
    "                # Append data to list\n",
    "                formatted_data.append([station_id, year] + values)\n",
    "\n",
    "        # Create DataFrame from formatted data\n",
    "        column_names = ['Station_ID', 'Year'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "        df_GHCN = pd.DataFrame(formatted_data, columns=column_names)\n",
    "        \n",
    "        # Replace -9999 with NaN\n",
    "        df_GHCN.replace(-9999, np.nan, inplace=True)\n",
    "        \n",
    "        # Format data - convert to degrees C\n",
    "        month_columns = [f'Month_{i}' for i in range(1, 13)]\n",
    "        df_GHCN[month_columns] = df_GHCN[month_columns].divide(100)\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9633663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GHCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f290a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHCN Station Meta data\n",
    "file_url = 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt'\n",
    "\n",
    "# Define the column widths\n",
    "column_widths = [11, 9, 10, 7, 3, 31]\n",
    "\n",
    "# Create DataFrame\n",
    "df_meta = pd.read_fwf(file_url, widths=column_widths, header=None, names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_GHCN))\n",
    "print(len(df_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbc69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on station ID\n",
    "df = pd.merge(df_GHCN, df_meta[['Station_ID', 'Latitude', 'Longitude', 'Name']], on='Station_ID', how='left')\n",
    "\n",
    "# Set index\n",
    "df = df.set_index('Station_ID')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fraction of NaN values\n",
    "nan_fraction = round(df.isna().mean().mean() * 100, 3)\n",
    "print(f'Fraction of NaN values in the DataFrame: {nan_fraction}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bbe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_coordinates(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame based on latitude and longitude conditions.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame with rows where latitude is between -90 and 90,\n",
    "    and longitude is between -180 and 180.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define latitude and longitude range conditions\n",
    "    lat_condition = (df['Latitude'] >= -90) & (df['Latitude'] <= 90)\n",
    "    lon_condition = (df['Longitude'] >= -180) & (df['Longitude'] <= 180)\n",
    "\n",
    "    # Apply the conditions to filter the DataFrame\n",
    "    df_filtered = df[lat_condition & lon_condition]\n",
    "    \n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(df) - len(df_filtered)\n",
    "    print(f'Number of rows with invalid coordinates (removed): {num_filtered}')\n",
    "\n",
    "    return df_filtered    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = filter_coordinates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f091f",
   "metadata": {},
   "source": [
    "# Xarray Conversion (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9fec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.Dataset.from_dataframe(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81b2d4",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9db4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Local imports\n",
    "GHCN_temp_url = 'https://data.giss.nasa.gov/pub/gistemp/ghcnm.tavg.qcf.dat'\n",
    "GHCN_meta_url = 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt'\n",
    "\n",
    "def get_GHCN_data(temp_url, meta_url):\n",
    "\n",
    "    '''\n",
    "    Retrieves and formats temperature data from the Global Historical Climatology Network (GHCN) dataset.\n",
    "\n",
    "    Args:\n",
    "    temp_url (str): The URL to the temperature data file in GHCN format.\n",
    "    meta_url (str): The URL to the metadata file containing station information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing temperature data with station metadata.\n",
    "    \n",
    "    This function sends an HTTP GET request to the temperature data URL, processes the data to create\n",
    "    a formatted DataFrame, replaces missing values with NaN, converts temperature values to degrees Celsius,\n",
    "    and merges the data with station metadata based on station IDs. The resulting DataFrame includes\n",
    "    columns for station latitude, longitude, and name, and is indexed by station IDs.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(temp_url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            \n",
    "            # Get the content of the response\n",
    "            file_data = response.content.decode(\"utf-8\")\n",
    "\n",
    "            # Create a list to store formatted data\n",
    "            formatted_data = []\n",
    "\n",
    "            # Loop through file data\n",
    "            for line in file_data.split('\\n'):\n",
    "                \n",
    "                # Check if line is not empty\n",
    "                if line.strip():\n",
    "                    \n",
    "                    # Extract relevant data\n",
    "                    # (Using code from GHCNV4Reader())\n",
    "                    station_id = line[:11]\n",
    "                    year = int(line[11:15])\n",
    "                    values = [int(line[i:i+5]) for i in range(19, 115, 8)]\n",
    "                    \n",
    "                    # Append data to list\n",
    "                    formatted_data.append([station_id, year] + values)\n",
    "\n",
    "            # Create DataFrame from formatted data\n",
    "            column_names = ['Station_ID', 'Year'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN = pd.DataFrame(formatted_data, columns=column_names)\n",
    "            \n",
    "            # Replace -9999 with NaN\n",
    "            df_GHCN.replace(-9999, np.nan, inplace=True)\n",
    "            \n",
    "            # Format data - convert to degrees C\n",
    "            month_columns = [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN[month_columns] = df_GHCN[month_columns].divide(100)\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    # Define the column widths, create meta data dataframe\n",
    "    column_widths = [11, 9, 10, 7, 3, 31]\n",
    "    df_meta = pd.read_fwf(meta_url, widths=column_widths, header=None,\n",
    "                          names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])\n",
    "    # Merge on station ID, set index\n",
    "    df = pd.merge(df_GHCN, df_meta[['Station_ID', 'Latitude', 'Longitude', 'Name']], on='Station_ID', how='left')\n",
    "    df = df.set_index('Station_ID')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def step0():\n",
    "    '''\n",
    "    Performs the initial data processing steps for the GHCN temperature dataset.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing filtered and formatted temperature data.\n",
    "    \n",
    "    This function retrieves temperature data from the Global Historical Climatology Network (GHCN) dataset,\n",
    "    processes and formats the data, and returns a DataFrame. The data is first fetched using specified URLs,\n",
    "    and is returned for further analysis.\n",
    "    '''\n",
    "    df_GHCN = get_GHCN_data(GHCN_temp_url, GHCN_meta_url)\n",
    "    return df_GHCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1cc2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step0_output = step0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a7afc",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "337fa352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def filter_coordinates(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame based on latitude and longitude conditions.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame with rows where latitude is between -90 and 90,\n",
    "    and longitude is between -180 and 180.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define latitude and longitude range conditions\n",
    "    lat_condition = (df['Latitude'] >= -90) & (df['Latitude'] <= 90)\n",
    "    lon_condition = (df['Longitude'] >= -180) & (df['Longitude'] <= 180)\n",
    "\n",
    "    # Apply the conditions to filter the DataFrame\n",
    "    df_filtered = df[lat_condition & lon_condition]\n",
    "    \n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(df) - len(df_filtered)\n",
    "    print(f'Number of rows with invalid coordinates (removed): {num_filtered}')\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "rules_text = '''\n",
    "CHM00052836  omit: 0-1948\n",
    "CHXLT909860  omit: 0-1950\n",
    "BL000085365  omit: 0-1930\n",
    "MXXLT948335  omit: 0-1952\n",
    "ASN00058012  omit: 0-1899\n",
    "ASN00084016  omit: 0-1899\n",
    "ASN00069018  omit: 0-1898\n",
    "NIXLT013080  omit: 0-1930\n",
    "NIXLT751359  omit: 0-9999\n",
    "CHXLT063941  omit: 0-1937\n",
    "CHM00054843  omit: 0-1937\n",
    "MXM00076373  omit: 0-9999\n",
    "USC00044022  omit: 0-9999\n",
    "USC00044025  omit: 0-9999\n",
    "CA002402332  omit: 2011-9999\n",
    "RSM00024266  omit: 2021/09\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def filter_stations_by_rules(dataframe, rules_text):\n",
    "    # Parse the rules from the provided text\n",
    "    rules = {}\n",
    "    for line in rules_text.split('\\n'):\n",
    "        if line.strip():\n",
    "            match = re.match(r'([A-Z0-9]+)\\s+omit:\\s+(\\S+)', line)\n",
    "            if match:\n",
    "                station_id, year_rule = match.groups()\n",
    "                rules[station_id] = year_rule\n",
    "\n",
    "    # Create a mask to identify rows to omit\n",
    "    mask = pd.Series(True, index=dataframe.index)\n",
    "\n",
    "    for station_id, year_rule in rules.items():\n",
    "        try:\n",
    "            # Split the year_rule into start and end years\n",
    "            start_year, end_year = map(int, year_rule.split('-'))\n",
    "        except ValueError:\n",
    "            # Handle cases like '2011/12' or '2012-9999'\n",
    "            if '/' in year_rule:\n",
    "                start_year = int(year_rule.split('/')[0])\n",
    "                end_year = start_year\n",
    "            elif '-' in year_rule:\n",
    "                start_year = int(year_rule.split('-')[0])\n",
    "                end_year = int(year_rule.split('-')[1])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Update the mask to False for the specified range of years for the station_id\n",
    "        mask &= ~((dataframe['Year'] >= start_year) & (dataframe['Year'] <= end_year) & (dataframe.index == station_id))\n",
    "\n",
    "    # Apply the mask to filter the DataFrame\n",
    "    filtered_dataframe = dataframe[mask]\n",
    "\n",
    "    return filtered_dataframe\n",
    "\n",
    "# Example usage:\n",
    "# filtered_df = filter_stations_by_rules(your_dataframe, rules_text)\n",
    "\n",
    "\n",
    "def step1(step0_output):\n",
    "    df_filtered = filter_coordinates(step0_output)\n",
    "    df_clean = filter_stations_by_rules(df_filtered, rules_text)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fc5a25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid coordinates (removed): 194947\n"
     ]
    }
   ],
   "source": [
    "step1_output = step1(step0_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "340294ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453166\n",
      "1257875\n"
     ]
    }
   ],
   "source": [
    "print(len(step0_output))\n",
    "print(len(step1_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebc28b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------- Running Step 0 ---------------|\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "dashes = '-'*15\n",
    "print(f'|{dashes} Running Step 0 {dashes}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6e4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
