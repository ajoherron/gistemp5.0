{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a0545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import itertools\n",
    "import math\n",
    "from io import StringIO\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013b1a4",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4577507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 0: Downloading Data\n",
    "\n",
    "Combining diverse inputs into a single dataset\n",
    "\n",
    "Inputs include:\n",
    "    - GHCN v4 data\n",
    "    - ERRST v5 data (later on?)\n",
    "'''\n",
    "\n",
    "# Standard library imports\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add the parent folder to sys.path\n",
    "# parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Local imports\n",
    "# from parameters.data import GHCN_temp_url, GHCN_meta_url\n",
    "GHCN_temp_url = 'https://data.giss.nasa.gov/pub/gistemp/ghcnm.tavg.qcf.dat'\n",
    "GHCN_meta_url = 'https://data.giss.nasa.gov/pub/gistemp/v4.inv'\n",
    "start_year = 1880\n",
    "\n",
    "# Local imports\n",
    "from parameters.data import GHCN_temp_url, GHCN_meta_url\n",
    "\n",
    "def get_GHCN_data(temp_url: str, meta_url: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Retrieves and formats temperature data from the Global Historical Climatology Network (GHCN) dataset.\n",
    "\n",
    "    Args:\n",
    "    temp_url (str): The URL to the temperature data file in GHCN format.\n",
    "    meta_url (str): The URL to the metadata file containing station information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing temperature data with station metadata.\n",
    "    \n",
    "    This function sends an HTTP GET request to the temperature data URL, processes the data to create\n",
    "    a formatted DataFrame, replaces missing values with NaN, converts temperature values to degrees Celsius,\n",
    "    and merges the data with station metadata based on station IDs. The resulting DataFrame includes\n",
    "    columns for station latitude, longitude, and name, and is indexed by station IDs.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(temp_url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            \n",
    "            # Get the content of the response\n",
    "            file_data: str = response.content.decode(\"utf-8\")\n",
    "\n",
    "            # Create a list to store formatted data\n",
    "            formatted_data = []\n",
    "\n",
    "            # Loop through file data\n",
    "            for line in file_data.split('\\n'):\n",
    "                \n",
    "                # Check if line is not empty\n",
    "                if line.strip():\n",
    "                    \n",
    "                    # Extract relevant data\n",
    "                    # (Using code from GHCNV4Reader())\n",
    "                    station_id: str = line[:11]\n",
    "                    year: int = int(line[11:15])\n",
    "                    values: List[int] = [int(line[i:i+5]) for i in range(19, 115, 8)]\n",
    "                    \n",
    "                    # Append data to list\n",
    "                    formatted_data.append([station_id, year] + values)\n",
    "\n",
    "            # Create DataFrame from formatted data\n",
    "            column_names: List[str] = ['Station_ID', 'Year'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN: pd.DataFrame = pd.DataFrame(formatted_data, columns=column_names)\n",
    "            \n",
    "            # Replace -9999 with NaN\n",
    "            df_GHCN.replace(-9999, np.nan, inplace=True)\n",
    "            \n",
    "            # Format data - convert to degrees C\n",
    "            month_columns: List[str] = [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN[month_columns] = df_GHCN[month_columns].divide(100)\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    # Define the column widths, create meta data dataframe\n",
    "    column_widths: List[int] = [11, 9, 10, 7, 3, 31]\n",
    "    df_meta: pd.DataFrame = pd.read_fwf(meta_url, widths=column_widths, header=None,\n",
    "                          names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])\n",
    "    # Merge on station ID, set index\n",
    "    df: pd.DataFrame = pd.merge(df_GHCN, df_meta[['Station_ID', 'Latitude', 'Longitude', 'Name']], on='Station_ID', how='left')\n",
    "    df = df.set_index('Station_ID')\n",
    "\n",
    "    return df\n",
    "\n",
    "def step0() -> pd.DataFrame:\n",
    "    '''\n",
    "    Performs the initial data processing steps for the GHCN temperature dataset.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing filtered and formatted temperature data.\n",
    "    \n",
    "    This function retrieves temperature data from the Global Historical Climatology Network (GHCN) dataset,\n",
    "    processes and formats the data, and returns a DataFrame. The data is first fetched using specified URLs,\n",
    "    and is returned for further analysis.\n",
    "    '''\n",
    "    df_GHCN: pd.DataFrame = get_GHCN_data(GHCN_temp_url, GHCN_meta_url)\n",
    "    return df_GHCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c396e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "step0_output = step0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ff7e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1961</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.68</td>\n",
       "      <td>7.69</td>\n",
       "      <td>11.24</td>\n",
       "      <td>15.95</td>\n",
       "      <td>15.66</td>\n",
       "      <td>14.77</td>\n",
       "      <td>14.09</td>\n",
       "      <td>11.70</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1962</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>6.31</td>\n",
       "      <td>9.04</td>\n",
       "      <td>13.77</td>\n",
       "      <td>15.06</td>\n",
       "      <td>13.89</td>\n",
       "      <td>11.59</td>\n",
       "      <td>9.90</td>\n",
       "      <td>3.19</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1963</td>\n",
       "      <td>-7.17</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>5.37</td>\n",
       "      <td>12.20</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.16</td>\n",
       "      <td>15.92</td>\n",
       "      <td>13.28</td>\n",
       "      <td>9.36</td>\n",
       "      <td>5.62</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1964</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.51</td>\n",
       "      <td>7.34</td>\n",
       "      <td>12.15</td>\n",
       "      <td>14.38</td>\n",
       "      <td>15.02</td>\n",
       "      <td>15.53</td>\n",
       "      <td>12.17</td>\n",
       "      <td>7.84</td>\n",
       "      <td>5.42</td>\n",
       "      <td>1.08</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1965</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5.86</td>\n",
       "      <td>9.83</td>\n",
       "      <td>14.96</td>\n",
       "      <td>14.83</td>\n",
       "      <td>14.73</td>\n",
       "      <td>13.73</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1966</td>\n",
       "      <td>21.80</td>\n",
       "      <td>20.40</td>\n",
       "      <td>18.40</td>\n",
       "      <td>16.90</td>\n",
       "      <td>14.30</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.10</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.70</td>\n",
       "      <td>19.80</td>\n",
       "      <td>20.90</td>\n",
       "      <td>21.10</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1967</td>\n",
       "      <td>21.10</td>\n",
       "      <td>19.90</td>\n",
       "      <td>18.90</td>\n",
       "      <td>19.20</td>\n",
       "      <td>15.10</td>\n",
       "      <td>13.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>13.80</td>\n",
       "      <td>16.60</td>\n",
       "      <td>20.80</td>\n",
       "      <td>19.90</td>\n",
       "      <td>19.10</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1968</td>\n",
       "      <td>21.80</td>\n",
       "      <td>20.00</td>\n",
       "      <td>19.30</td>\n",
       "      <td>18.20</td>\n",
       "      <td>15.60</td>\n",
       "      <td>10.80</td>\n",
       "      <td>13.70</td>\n",
       "      <td>16.30</td>\n",
       "      <td>17.60</td>\n",
       "      <td>21.80</td>\n",
       "      <td>18.40</td>\n",
       "      <td>20.70</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1969</td>\n",
       "      <td>20.90</td>\n",
       "      <td>21.50</td>\n",
       "      <td>19.50</td>\n",
       "      <td>18.30</td>\n",
       "      <td>14.10</td>\n",
       "      <td>13.10</td>\n",
       "      <td>11.60</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.80</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.40</td>\n",
       "      <td>19.10</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1970</td>\n",
       "      <td>20.70</td>\n",
       "      <td>19.90</td>\n",
       "      <td>19.30</td>\n",
       "      <td>17.20</td>\n",
       "      <td>15.60</td>\n",
       "      <td>13.30</td>\n",
       "      <td>13.30</td>\n",
       "      <td>15.40</td>\n",
       "      <td>20.40</td>\n",
       "      <td>20.30</td>\n",
       "      <td>21.30</td>\n",
       "      <td>21.50</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1453206 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Year  Month_1  Month_2  Month_3  Month_4  Month_5  Month_6  \\\n",
       "Station_ID                                                                \n",
       "ACW00011604  1961    -0.93     2.32     4.68     7.69    11.24    15.95   \n",
       "ACW00011604  1962     1.09     0.81    -1.58     6.31     9.04    13.77   \n",
       "ACW00011604  1963    -7.17    -5.57    -1.03     5.37    12.20    16.23   \n",
       "ACW00011604  1964     0.58    -0.89     0.51     7.34    12.15    14.38   \n",
       "ACW00011604  1965     0.40    -1.09     0.34     5.86     9.83    14.96   \n",
       "...           ...      ...      ...      ...      ...      ...      ...   \n",
       "ZIXLT622116  1966    21.80    20.40    18.40    16.90    14.30    12.80   \n",
       "ZIXLT622116  1967    21.10    19.90    18.90    19.20    15.10    13.50   \n",
       "ZIXLT622116  1968    21.80    20.00    19.30    18.20    15.60    10.80   \n",
       "ZIXLT622116  1969    20.90    21.50    19.50    18.30    14.10    13.10   \n",
       "ZIXLT622116  1970    20.70    19.90    19.30    17.20    15.60    13.30   \n",
       "\n",
       "             Month_7  Month_8  Month_9  Month_10  Month_11  Month_12  \\\n",
       "Station_ID                                                             \n",
       "ACW00011604    15.66    14.77    14.09     11.70      5.06     -0.43   \n",
       "ACW00011604    15.06    13.89    11.59      9.90      3.19     -1.30   \n",
       "ACW00011604    16.16    15.92    13.28      9.36      5.62     -1.12   \n",
       "ACW00011604    15.02    15.53    12.17      7.84      5.42      1.08   \n",
       "ACW00011604    14.83    14.73    13.73      9.70      0.27     -1.82   \n",
       "...              ...      ...      ...       ...       ...       ...   \n",
       "ZIXLT622116    12.10    14.60    17.70     19.80     20.90     21.10   \n",
       "ZIXLT622116    11.00    13.80    16.60     20.80     19.90     19.10   \n",
       "ZIXLT622116    13.70    16.30    17.60     21.80     18.40     20.70   \n",
       "ZIXLT622116    11.60    14.60    17.80     21.00     20.40     19.10   \n",
       "ZIXLT622116    13.30    15.40    20.40     20.30     21.30     21.50   \n",
       "\n",
       "             Latitude  Longitude Name  \n",
       "Station_ID                             \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "...               ...        ...  ...  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "\n",
       "[1453206 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step0_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad6e23",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b065356",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1: Removal of bad data\n",
    "\n",
    "Drop or adjust certain records (or parts of records).\n",
    "This includes outliers / out of range reports.\n",
    "Determined using configuration file.\n",
    "    <TO-DO> Figure out if this method is ideal.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Add the parent folder to sys.path\n",
    "# parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Local imports\n",
    "# from parameters.data import drop_rules\n",
    "drop_rules = '''\n",
    "CHM00052836  omit: 0-1948\n",
    "CHXLT909860  omit: 0-1950\n",
    "BL000085365  omit: 0-1930\n",
    "MXXLT948335  omit: 0-1952\n",
    "ASN00058012  omit: 0-1899\n",
    "ASN00084016  omit: 0-1899\n",
    "ASN00069018  omit: 0-1898\n",
    "NIXLT013080  omit: 0-1930\n",
    "NIXLT751359  omit: 0-9999\n",
    "CHXLT063941  omit: 0-1937\n",
    "CHM00054843  omit: 0-1937\n",
    "MXM00076373  omit: 0-9999\n",
    "USC00044022  omit: 0-9999\n",
    "USC00044025  omit: 0-9999\n",
    "CA002402332  omit: 2011-9999\n",
    "RSM00024266  omit: 2021/09\n",
    "'''\n",
    "\n",
    "\n",
    "def filter_coordinates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters a DataFrame based on latitude and longitude conditions.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame with rows where latitude is between -90 and 90,\n",
    "    and longitude is between -180 and 180.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define latitude and longitude range conditions\n",
    "    lat_condition = (df['Latitude'] >= -90) & (df['Latitude'] <= 90)\n",
    "    lon_condition = (df['Longitude'] >= -180) & (df['Longitude'] <= 180)\n",
    "\n",
    "    # Apply the conditions to filter the DataFrame\n",
    "    df_filtered = df[lat_condition & lon_condition]\n",
    "    \n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(df) - len(df_filtered)\n",
    "    print(f'Number of rows with invalid coordinates (removed): {num_filtered}')\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def filter_stations_by_rules(dataframe: pd.DataFrame, rules_text: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters a DataFrame of climate station data based on exclusion rules specified in a text format.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing climate station data.\n",
    "        rules_text (str): A string containing exclusion rules for specific stations and years.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame with stations omitted based on the provided rules.\n",
    "\n",
    "    Rules Format:\n",
    "        The 'rules_text' should be formatted as follows:\n",
    "        - Each rule is represented as a single line in the text.\n",
    "        - Each line should start with the station ID followed by exclusion rules.\n",
    "        - Exclusion rules consist of 'omit:' followed by the years to exclude, e.g., 'omit: 2000-2010'.\n",
    "        - Years can be specified as a single year (e.g., 'omit: 2000') or as a range (e.g., 'omit: 2000-2010').\n",
    "        - Year ranges can also be specified using '/' (e.g., 'omit: 2000/2002').\n",
    "\n",
    "    Example:\n",
    "        rules_text = '''\n",
    "            CHM00052836  omit: 0-1948\n",
    "            CHXLT909860  omit: 0-1950\n",
    "            BL000085365  omit: 0-1930\n",
    "            ...\n",
    "        '''\n",
    "\n",
    "    This function takes the provided rules and applies them to the input DataFrame,\n",
    "    resulting in a new DataFrame with stations excluded based on the specified rules.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the rules from the provided text\n",
    "    rules = {}\n",
    "    for line in rules_text.split('\\n'):\n",
    "        if line.strip():\n",
    "            match = re.match(r'([A-Z0-9]+)\\s+omit:\\s+(\\S+)', line)\n",
    "            if match:\n",
    "                station_id, year_rule = match.groups()\n",
    "                rules[station_id] = year_rule\n",
    "\n",
    "    # Create a mask to identify rows to omit\n",
    "    mask = pd.Series(True, index=dataframe.index)\n",
    "\n",
    "    for station_id, year_rule in rules.items():\n",
    "        try:\n",
    "            # Split the year_rule into start and end years\n",
    "            start_year, end_year = map(int, year_rule.split('-'))\n",
    "        except ValueError:\n",
    "            # Handle cases like '2011/12' or '2012-9999'\n",
    "            if '/' in year_rule:\n",
    "                start_year = int(year_rule.split('/')[0])\n",
    "                end_year = start_year\n",
    "            elif '-' in year_rule:\n",
    "                start_year = int(year_rule.split('-')[0])\n",
    "                end_year = int(year_rule.split('-')[1])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Update the mask to False for the specified range of years for the station_id\n",
    "        mask &= ~((dataframe['Year'] >= start_year) & (dataframe['Year'] <= end_year) & (dataframe.index == station_id))\n",
    "\n",
    "    # Apply the mask to filter the DataFrame\n",
    "    filtered_dataframe = dataframe[mask]\n",
    "\n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(dataframe) - len(filtered_dataframe)\n",
    "    print(f'Number of rows removed according to station exclusion rules: {num_filtered}')\n",
    "\n",
    "    return filtered_dataframe\n",
    "\n",
    "def step1(step0_output: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies data filtering and cleaning operations to the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        step0_output (pd.DataFrame): The initial DataFrame containing climate station data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned and filtered DataFrame ready for further analysis.\n",
    "\n",
    "    This function serves as a data processing step by applying two essential filtering operations:\n",
    "    1. `filter_coordinates`: Filters the DataFrame based on geographical coordinates, retaining relevant stations.\n",
    "    2. `filter_stations_by_rules`: Filters the DataFrame based on exclusion rules, omitting specified stations and years.\n",
    "\n",
    "    The resulting DataFrame is cleaned of irrelevant stations and years according to specified rules\n",
    "    and is ready for subsequent data analysis or visualization.\n",
    "    \"\"\"\n",
    "        \n",
    "    df_filtered = filter_coordinates(step0_output)\n",
    "    df_clean = filter_stations_by_rules(df_filtered, drop_rules)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15764ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid coordinates (removed): 0\n",
      "Number of rows removed according to station exclusion rules: 524\n"
     ]
    }
   ],
   "source": [
    "step1_output = step1(step0_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2125c5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1961</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.68</td>\n",
       "      <td>7.69</td>\n",
       "      <td>11.24</td>\n",
       "      <td>15.95</td>\n",
       "      <td>15.66</td>\n",
       "      <td>14.77</td>\n",
       "      <td>14.09</td>\n",
       "      <td>11.70</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1962</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>6.31</td>\n",
       "      <td>9.04</td>\n",
       "      <td>13.77</td>\n",
       "      <td>15.06</td>\n",
       "      <td>13.89</td>\n",
       "      <td>11.59</td>\n",
       "      <td>9.90</td>\n",
       "      <td>3.19</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1963</td>\n",
       "      <td>-7.17</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>5.37</td>\n",
       "      <td>12.20</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.16</td>\n",
       "      <td>15.92</td>\n",
       "      <td>13.28</td>\n",
       "      <td>9.36</td>\n",
       "      <td>5.62</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1964</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.51</td>\n",
       "      <td>7.34</td>\n",
       "      <td>12.15</td>\n",
       "      <td>14.38</td>\n",
       "      <td>15.02</td>\n",
       "      <td>15.53</td>\n",
       "      <td>12.17</td>\n",
       "      <td>7.84</td>\n",
       "      <td>5.42</td>\n",
       "      <td>1.08</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1965</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5.86</td>\n",
       "      <td>9.83</td>\n",
       "      <td>14.96</td>\n",
       "      <td>14.83</td>\n",
       "      <td>14.73</td>\n",
       "      <td>13.73</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1966</td>\n",
       "      <td>21.80</td>\n",
       "      <td>20.40</td>\n",
       "      <td>18.40</td>\n",
       "      <td>16.90</td>\n",
       "      <td>14.30</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.10</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.70</td>\n",
       "      <td>19.80</td>\n",
       "      <td>20.90</td>\n",
       "      <td>21.10</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1967</td>\n",
       "      <td>21.10</td>\n",
       "      <td>19.90</td>\n",
       "      <td>18.90</td>\n",
       "      <td>19.20</td>\n",
       "      <td>15.10</td>\n",
       "      <td>13.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>13.80</td>\n",
       "      <td>16.60</td>\n",
       "      <td>20.80</td>\n",
       "      <td>19.90</td>\n",
       "      <td>19.10</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1968</td>\n",
       "      <td>21.80</td>\n",
       "      <td>20.00</td>\n",
       "      <td>19.30</td>\n",
       "      <td>18.20</td>\n",
       "      <td>15.60</td>\n",
       "      <td>10.80</td>\n",
       "      <td>13.70</td>\n",
       "      <td>16.30</td>\n",
       "      <td>17.60</td>\n",
       "      <td>21.80</td>\n",
       "      <td>18.40</td>\n",
       "      <td>20.70</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1969</td>\n",
       "      <td>20.90</td>\n",
       "      <td>21.50</td>\n",
       "      <td>19.50</td>\n",
       "      <td>18.30</td>\n",
       "      <td>14.10</td>\n",
       "      <td>13.10</td>\n",
       "      <td>11.60</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.80</td>\n",
       "      <td>21.00</td>\n",
       "      <td>20.40</td>\n",
       "      <td>19.10</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1970</td>\n",
       "      <td>20.70</td>\n",
       "      <td>19.90</td>\n",
       "      <td>19.30</td>\n",
       "      <td>17.20</td>\n",
       "      <td>15.60</td>\n",
       "      <td>13.30</td>\n",
       "      <td>13.30</td>\n",
       "      <td>15.40</td>\n",
       "      <td>20.40</td>\n",
       "      <td>20.30</td>\n",
       "      <td>21.30</td>\n",
       "      <td>21.50</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1452682 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Year  Month_1  Month_2  Month_3  Month_4  Month_5  Month_6  \\\n",
       "Station_ID                                                                \n",
       "ACW00011604  1961    -0.93     2.32     4.68     7.69    11.24    15.95   \n",
       "ACW00011604  1962     1.09     0.81    -1.58     6.31     9.04    13.77   \n",
       "ACW00011604  1963    -7.17    -5.57    -1.03     5.37    12.20    16.23   \n",
       "ACW00011604  1964     0.58    -0.89     0.51     7.34    12.15    14.38   \n",
       "ACW00011604  1965     0.40    -1.09     0.34     5.86     9.83    14.96   \n",
       "...           ...      ...      ...      ...      ...      ...      ...   \n",
       "ZIXLT622116  1966    21.80    20.40    18.40    16.90    14.30    12.80   \n",
       "ZIXLT622116  1967    21.10    19.90    18.90    19.20    15.10    13.50   \n",
       "ZIXLT622116  1968    21.80    20.00    19.30    18.20    15.60    10.80   \n",
       "ZIXLT622116  1969    20.90    21.50    19.50    18.30    14.10    13.10   \n",
       "ZIXLT622116  1970    20.70    19.90    19.30    17.20    15.60    13.30   \n",
       "\n",
       "             Month_7  Month_8  Month_9  Month_10  Month_11  Month_12  \\\n",
       "Station_ID                                                             \n",
       "ACW00011604    15.66    14.77    14.09     11.70      5.06     -0.43   \n",
       "ACW00011604    15.06    13.89    11.59      9.90      3.19     -1.30   \n",
       "ACW00011604    16.16    15.92    13.28      9.36      5.62     -1.12   \n",
       "ACW00011604    15.02    15.53    12.17      7.84      5.42      1.08   \n",
       "ACW00011604    14.83    14.73    13.73      9.70      0.27     -1.82   \n",
       "...              ...      ...      ...       ...       ...       ...   \n",
       "ZIXLT622116    12.10    14.60    17.70     19.80     20.90     21.10   \n",
       "ZIXLT622116    11.00    13.80    16.60     20.80     19.90     19.10   \n",
       "ZIXLT622116    13.70    16.30    17.60     21.80     18.40     20.70   \n",
       "ZIXLT622116    11.60    14.60    17.80     21.00     20.40     19.10   \n",
       "ZIXLT622116    13.30    15.40    20.40     20.30     21.30     21.50   \n",
       "\n",
       "             Latitude  Longitude Name  \n",
       "Station_ID                             \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "ACW00011604   57.7667    11.8667   VE  \n",
       "...               ...        ...  ...  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  -19.4300    29.7500  ELO  \n",
       "\n",
       "[1452682 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6004502",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39fb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0e24b",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42251e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 3: Gridding of cells\n",
    "\n",
    "There are 8000 cells across the globe.\n",
    "Each cell's values are computed using station records within a 1200km radius.\n",
    "    - Contributions are weighted according to distance to cell center\n",
    "    (linearly decreasing to 0 at distance 1200km)\n",
    "'''\n",
    "\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "\n",
    "def calculate_area(row: Series) -> float:\n",
    "    earth_radius_km: float = 6371.0\n",
    "    delta_longitude: float = np.radians(row['Eastern'] - row['Western'])\n",
    "    southern_latitude: float = np.radians(row['Southern'])\n",
    "    northern_latitude: float = np.radians(row['Northern'])\n",
    "    area: float = (earth_radius_km ** 2) * delta_longitude * (np.sin(northern_latitude) - np.sin(southern_latitude))\n",
    "    return area\n",
    "\n",
    "\n",
    "def calculate_center_coordinates(row: pd.Series) -> Tuple[float, float]:\n",
    "    \"\"\"Calculate the center latitude and longitude for a given box.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A Pandas Series representing a row of the DataFrame with ('southern', 'northern', 'western', 'eastern') coordinates.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple containing the center latitude and longitude.\n",
    "    \"\"\"\n",
    "    center_latitude = 0.5 * (math.sin(row['Southern'] * math.pi / 180) + math.sin(row['Northern'] * math.pi / 180))\n",
    "    center_longitude = 0.5 * (row['Western'] + row['Eastern'])\n",
    "    center_latitude = math.asin(center_latitude) * 180 / math.pi\n",
    "    return center_latitude, center_longitude\n",
    "\n",
    "\n",
    "def generate_80_cell_grid() -> pd.DataFrame:\n",
    "    \"\"\"Generate an 80-cell grid DataFrame with columns for southern, northern, western, eastern,\n",
    "    center_latitude, and center_longitude coordinates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The generated DataFrame.\n",
    "    \"\"\"\n",
    "    grid_data = []\n",
    "    \n",
    "    # Number of horizontal boxes in each band\n",
    "    # (proportional to the thickness of each band)\n",
    "    band_boxes = [4, 8, 12, 16]\n",
    "    \n",
    "    # Sines of latitudes\n",
    "    band_altitude = [1, 0.9, 0.7, 0.4, 0]\n",
    "\n",
    "    # Generate the 40 cells in the northern hemisphere\n",
    "    for band in range(len(band_boxes)):\n",
    "        n = band_boxes[band]\n",
    "        for i in range(n):\n",
    "            lats = 180 / math.pi * math.asin(band_altitude[band + 1])\n",
    "            latn = 180 / math.pi * math.asin(band_altitude[band])\n",
    "            lonw = -180 + 360 * float(i) / n\n",
    "            lone = -180 + 360 * float(i + 1) / n\n",
    "            box = (lats, latn, lonw, lone)\n",
    "            grid_data.append(box)\n",
    "\n",
    "    # Generate the 40 cells in the southern hemisphere by reversing the northern hemisphere cells\n",
    "    for box in grid_data[::-1]:\n",
    "        grid_data.append((-box[1], -box[0], box[2], box[3]))\n",
    "\n",
    "    # Create a DataFrame from the grid data\n",
    "    df = pd.DataFrame(grid_data, columns=['Southern', 'Northern', 'Western', 'Eastern'])\n",
    "\n",
    "    # Calculate center coordinates for each box and add them as new columns\n",
    "    center_coords = df.apply(calculate_center_coordinates, axis=1)\n",
    "    df[['Center_Latitude', 'Center_Longitude']] = pd.DataFrame(center_coords.tolist(), index=df.index)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def interpolate(x: float, y: float, p: float) -> float:\n",
    "    return y * p + (1 - p) * x\n",
    "\n",
    "\n",
    "def generate_8000_cell_grid(grid_80):\n",
    "\n",
    "    # Initialize an empty list to store subboxes\n",
    "    subbox_list = []\n",
    "\n",
    "    for index, row in grid_80.iterrows():\n",
    "        alts = math.sin(row['Southern'] * math.pi / 180)\n",
    "        altn = math.sin(row['Northern'] * math.pi / 180)\n",
    "\n",
    "        for y in range(10):\n",
    "            s = 180 * math.asin(interpolate(alts, altn, y * 0.1)) / math.pi\n",
    "            n = 180 * math.asin(interpolate(alts, altn, (y + 1) * 0.1)) / math.pi\n",
    "            for x in range(10):\n",
    "                w = interpolate(row['Western'], row['Eastern'], x * 0.1)\n",
    "                e = interpolate(row['Western'], row['Eastern'], (x + 1) * 0.1)\n",
    "\n",
    "                # Create a DataFrame for the subbox\n",
    "                subbox_df = pd.DataFrame({'Southern': [s], 'Northern': [n], 'Western': [w], 'Eastern': [e]})\n",
    "\n",
    "                # Append the subbox DataFrame to the list\n",
    "                subbox_list.append(subbox_df)\n",
    "\n",
    "    # Concatenate all subboxes into a single DataFrame\n",
    "    grid_8000 = pd.concat(subbox_list, ignore_index=True)\n",
    "\n",
    "    # Calculate center coordinates for each box and add them as new columns\n",
    "    center_coords = grid_8000.apply(calculate_center_coordinates, axis=1)\n",
    "    grid_8000[['Center_Latitude', 'Center_Longitude']] = pd.DataFrame(center_coords.tolist(), index=grid_8000.index)\n",
    "\n",
    "    # Calculate area of all 8000 cells\n",
    "    grid_8000['Area'] = grid_8000.apply(calculate_area, axis=1)\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    return grid_8000\n",
    "\n",
    "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the spherical distance (in kilometers) between two pairs of\n",
    "    latitude and longitude coordinates using the Haversine formula.\n",
    "\n",
    "    Args:\n",
    "        lat1 (float): Latitude of the first point in degrees.\n",
    "        lon1 (float): Longitude of the first point in degrees.\n",
    "        lat2 (float): Latitude of the second point in degrees.\n",
    "        lon2 (float): Longitude of the second point in degrees.\n",
    "\n",
    "    Returns:\n",
    "        float: Spherical distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    # Radius of the Earth in kilometers\n",
    "    radius: float = 6371.0  # Earth's mean radius\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat: float = lat2 - lat1\n",
    "    dlon: float = lon2 - lon1\n",
    "\n",
    "    a: float = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c: float = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    distance: float = radius * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def linearly_decreasing_weight(distance: float, max_distance: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate a linearly decreasing weight based on the given distance\n",
    "    and maximum distance.\n",
    "\n",
    "    Args:\n",
    "        distance (float): The distance at which you want to calculate the weight.\n",
    "        max_distance (float): The maximum distance at which the weight becomes 0.\n",
    "\n",
    "    Returns:\n",
    "        float: The linearly decreasing weight, ranging from 1 to 0.\n",
    "    \"\"\"\n",
    "    # Ensure that distance is within the valid range [0, max_distance]\n",
    "    distance: float = max(0, min(distance, max_distance))\n",
    "\n",
    "    # Calculate the weight as a linear interpolation\n",
    "    weight: float = 1.0 - (distance / max_distance)\n",
    "    \n",
    "    return weight\n",
    "\n",
    "def normalize_dict_values(d):\n",
    "    # Calculate the sum of all values in the dictionary\n",
    "    total = sum(d.values())\n",
    "    \n",
    "    # Check if the total is not zero to avoid division by zero\n",
    "    if total != 0:\n",
    "        # Normalize each value by dividing by the total\n",
    "        normalized_dict = {key: value / total for key, value in d.items()}\n",
    "        return normalized_dict\n",
    "    else:\n",
    "        # Handle the case where the total is zero (all values are zero)\n",
    "        return d  # Return the original dictionary\n",
    "\n",
    "def nearby_stations(grid_df, station_df):\n",
    "\n",
    "    # Initialize an empty list to store station IDs and weights as dictionaries\n",
    "    station_weights_within_radius = []\n",
    "\n",
    "    # Maximum distance for the weight calculation (e.g., 1200.0 km)\n",
    "    max_distance = 1200.0\n",
    "\n",
    "    # Use tqdm to track progress\n",
    "    for index, row in tqdm(grid_df.iterrows(), total=len(grid_df), desc=\"Processing\"):\n",
    "        center_lat = row['Center_Latitude']\n",
    "        center_lon = row['Center_Longitude']\n",
    "\n",
    "        # Calculate distances for each station in station_df\n",
    "        distances = station_df.apply(lambda x: haversine_distance(center_lat, center_lon, x['Latitude'], x['Longitude']), axis=1)\n",
    "\n",
    "        # Find station IDs within the specified radius\n",
    "        nearby_stations = station_df[distances <= max_distance]\n",
    "\n",
    "        # Calculate weights for each nearby station\n",
    "        weights = nearby_stations.apply(lambda x: linearly_decreasing_weight(distances[x.name], max_distance), axis=1)\n",
    "\n",
    "        # Create a dictionary of station IDs and weights\n",
    "        station_weights = dict(zip(nearby_stations['Station_ID'], weights))\n",
    "        \n",
    "        # Normalize weights to sum to 1\n",
    "        station_weights = normalize_dict_values(station_weights)\n",
    "\n",
    "        # Append the dictionary to the result list\n",
    "        station_weights_within_radius.append(station_weights)\n",
    "\n",
    "    # Add the list of station IDs and weights as a new column\n",
    "    grid_df['Nearby_Stations'] = station_weights_within_radius\n",
    "\n",
    "    # Set index name\n",
    "    grid_df.index.name = 'Box_Number'\n",
    "    \n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213c3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 80 cell grid (boxes)\n",
    "grid_80 = generate_80_cell_grid()\n",
    "grid_80['Area'] = grid_80.apply(calculate_area, axis=1)\n",
    "\n",
    "# Create 8000 cell grid (subboxes)\n",
    "grid_8000 = generate_8000_cell_grid(grid_80)\n",
    "grid_8000['Area'] = grid_8000.apply(calculate_area, axis=1)\n",
    "\n",
    "# Create station metadata dataframe\n",
    "meta_url = 'https://data.giss.nasa.gov/pub/gistemp/v4.inv'\n",
    "column_widths: List[int] = [11, 9, 10, 7, 3, 31]\n",
    "station_df: pd.DataFrame = pd.read_fwf(meta_url, widths=column_widths, header=None,\n",
    "                          names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea14611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████████████████| 80/80 [00:06<00:00, 12.31it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_80 = nearby_stations(grid_80, station_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b54a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_8000 = nearby_stations(grid_8000, station_df)\n",
    "# grid_8000.to_csv('grid_8000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d610c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in 8000 cell grid\n",
    "grid_8000 = pd.read_csv('grid_8000.csv')\n",
    "grid_8000 = grid_8000.set_index('Box_Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77402833",
   "metadata": {},
   "source": [
    "# Step 4: SST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f19a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping for now\n",
    "# Should be consolidated into step 0 / 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f9df3",
   "metadata": {},
   "source": [
    "# Step 5: Anomalyzing Data (yearRow algorithm)\n",
    "\n",
    "Aside: need to figure out what to do about missing data in 1951\n",
    "\n",
    "- Calculate monthly averages for each station (DRAFT)\n",
    "- Use monthly averages to calculate yearly anomalies for each station (DRAFT)\n",
    "- Create a gridded anomaly dataframe\n",
    "    - For each cell:\n",
    "        - Collect all anomalies from stations within 1200 kilometers (and their weights) (DRAFT)\n",
    "        - Multiply each station's rows by their weights (DRAFT)\n",
    "        - Sum the rows for the same year (DRAFT)\n",
    "        - That's the time series for the cell (DRAFT)\n",
    "            - (NOTE: each cell will be a dataframe, rather than a single row)\n",
    "    \n",
    "    - (DIFFICULT TO DO EFFICIENTLY/QUICKLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8841e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_averages(df, start_year, end_year):\n",
    "    \n",
    "    # Copy output from step 1\n",
    "    df = step1_output.copy()\n",
    "\n",
    "    # Collect list of all stations\n",
    "    all_stations = sorted(list(df.index.unique()))\n",
    "\n",
    "    # Create dataframe of only monthly temperature values\n",
    "    station_months = df.drop(columns=['Latitude', 'Longitude', 'Name'])\n",
    "\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    for station_i in tqdm(all_stations):\n",
    "        monthly_values = station_months.loc[station_i]\n",
    "        baseline_yearly_averages = monthly_values[(monthly_values['Year'] >= start_year) & (monthly_values['Year'] <= end_year)]\n",
    "        baseline_monthly_averages = baseline_yearly_averages.drop(columns=['Year']).mean()\n",
    "        dfs.append(baseline_monthly_averages)\n",
    "\n",
    "    # Concatenate all DataFrames in the list\n",
    "    monthly_station_averages = pd.concat(dfs, axis=1).T\n",
    "\n",
    "    # Set the index to station_i for each row\n",
    "    monthly_station_averages.index = all_stations\n",
    "    \n",
    "    return monthly_station_averages\n",
    "\n",
    "def calculate_anomalies(df, monthly_averages_df):\n",
    "    \n",
    "    # Calculate temperature anomalies for each station and each month\n",
    "    anomalies = df.iloc[:, 1:13] - monthly_averages_df\n",
    "\n",
    "    # Add the 'Year', 'Latitude', 'Longitude', and 'Name' columns back to the anomalies DataFrame\n",
    "    anomalies[['Year', 'Latitude', 'Longitude', 'Name']] = df[['Year', 'Latitude', 'Longitude', 'Name']]\n",
    "\n",
    "    # Set the index of the anomalies DataFrame to match the original station IDs\n",
    "    anomalies.index = df.index\n",
    "\n",
    "    return anomalies\n",
    "\n",
    "def calculate_8000_cell_anomaly(anomaly_df):\n",
    "    \n",
    "    # Suppress the SettingWithCopyWarning\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    monthly_columns = []\n",
    "    for i in range(1, 13):\n",
    "        monthly_columns.append('Month_' + str(i))\n",
    "\n",
    "    anomaly_8000 = []\n",
    "    for i in tqdm(range(len(grid_8000))):\n",
    "        cell = grid_8000.iloc[i]\n",
    "\n",
    "        station_dict = eval(cell['Nearby_Stations'])\n",
    "        df_weighted = anomaly_df.loc[anomaly_df.index.isin(station_dict.keys())]\n",
    "\n",
    "        for station_id, weight in station_dict.items():\n",
    "            if station_id in df_weighted.index:\n",
    "                df_weighted.loc[station_id, monthly_columns] = df_weighted.loc[station_id, monthly_columns] * weight\n",
    "\n",
    "        yearly_anomaly = df_weighted.groupby('Year').sum(numeric_only=True).reset_index()\n",
    "        anomaly_8000.append(yearly_anomaly)\n",
    "    return anomaly_8000\n",
    "        \n",
    "def add_box_number_column(grid_8000, grid_80):\n",
    "    # Initialize an empty list to store box numbers\n",
    "    box_numbers = []\n",
    "\n",
    "    # Iterate through each cell in the grid_8000 DataFrame\n",
    "    for index, row in grid_8000.iterrows():\n",
    "        # Get the latitude and longitude of the center of the cell\n",
    "        cell_latitude = row['Center_Latitude']\n",
    "        cell_longitude = row['Center_Longitude']\n",
    "\n",
    "        # Find the box in grid_80 that contains this cell\n",
    "        for box_number, box_row in grid_80.iterrows():\n",
    "            if (\n",
    "                box_row['Southern'] <= cell_latitude <= box_row['Northern'] and\n",
    "                box_row['Western'] <= cell_longitude <= box_row['Eastern']\n",
    "            ):\n",
    "                box_numbers.append(box_number)\n",
    "                break  # No need to check other boxes\n",
    "\n",
    "    # Add the box numbers as a new column to grid_8000\n",
    "    grid_8000['Box_Number'] = box_numbers\n",
    "\n",
    "    return grid_8000\n",
    "\n",
    "def calculate_80_cell_anomaly(anomaly_8000):\n",
    "    df = anomaly_8000.copy()\n",
    "    anomaly_80 = []\n",
    "\n",
    "    for box in tqdm(range(len(grid_80))):\n",
    "        box_dfs = df[box:(box+1)*100]\n",
    "\n",
    "        dfs_with_source = [(df, source) for source, df in enumerate(box_dfs)]\n",
    "        concatenated_dfs = [df.assign(Source=source) for df, source in dfs_with_source]\n",
    "        concatenated_df = pd.concat(concatenated_dfs)\n",
    "\n",
    "        # Group by 'Year' and calculate the mean for each year\n",
    "        grouped = concatenated_df.groupby('Year')\n",
    "\n",
    "        # Calculate the mean for each year while ignoring NaN values\n",
    "        average_df = grouped.mean(numeric_only=True)\n",
    "\n",
    "        # Reset the index to have 'Year' as a regular column\n",
    "        average_df = average_df.reset_index()\n",
    "\n",
    "        anomaly_80.append(average_df)\n",
    "        \n",
    "    return anomaly_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daa2c1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 27686/27686 [00:08<00:00, 3099.16it/s]\n",
      "100%|███████████████████████████████████████| 8000/8000 [29:48<00:00,  4.47it/s]\n",
      "100%|███████████████████████████████████████████| 80/80 [00:39<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate monthly averages\n",
    "monthly_averages_df = calculate_monthly_averages(step1_output, 1951, 1980)\n",
    "\n",
    "# Calculate anomalies for all stations / years\n",
    "anomaly_df = calculate_anomalies(step1_output, monthly_averages_df)\n",
    "\n",
    "# Create list of dataframes for anomalies for 8000 cell grid\n",
    "anomaly_8000 = calculate_8000_cell_anomaly(anomaly_df)\n",
    "\n",
    "# Add box number to each dataframe in anomaly_8000 list\n",
    "#grid_8000 = add_box_number_column(grid_8000, grid_80)\n",
    "#anomaly_8000 = [df.assign(Box_Number=grid_8000['Box_Number']) for df in anomaly_8000]\n",
    "\n",
    "# Create list of dataframes for anomalies for 80 cell grid\n",
    "anomaly_80 = calculate_80_cell_anomaly(anomaly_8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71da03f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014430</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>-0.006398</td>\n",
       "      <td>-0.017866</td>\n",
       "      <td>57.1553</td>\n",
       "      <td>-170.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1840</td>\n",
       "      <td>-0.023147</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>-0.005059</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.002771</td>\n",
       "      <td>-0.008608</td>\n",
       "      <td>-0.021232</td>\n",
       "      <td>-0.050500</td>\n",
       "      <td>57.1553</td>\n",
       "      <td>-170.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1841</td>\n",
       "      <td>-0.007719</td>\n",
       "      <td>-0.022144</td>\n",
       "      <td>-0.041254</td>\n",
       "      <td>0.013252</td>\n",
       "      <td>-0.007577</td>\n",
       "      <td>-0.002464</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.000991</td>\n",
       "      <td>-0.009201</td>\n",
       "      <td>-0.017079</td>\n",
       "      <td>-0.029733</td>\n",
       "      <td>57.1553</td>\n",
       "      <td>-170.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1842</td>\n",
       "      <td>-0.051627</td>\n",
       "      <td>-0.064865</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-0.014042</td>\n",
       "      <td>-0.012324</td>\n",
       "      <td>-0.014331</td>\n",
       "      <td>-0.007447</td>\n",
       "      <td>-0.009897</td>\n",
       "      <td>-0.006924</td>\n",
       "      <td>-0.006234</td>\n",
       "      <td>-0.004618</td>\n",
       "      <td>-0.011339</td>\n",
       "      <td>57.1553</td>\n",
       "      <td>-170.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1843</td>\n",
       "      <td>-0.068241</td>\n",
       "      <td>-0.019770</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>-0.010482</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>-0.000991</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>-0.006398</td>\n",
       "      <td>-0.024393</td>\n",
       "      <td>57.1553</td>\n",
       "      <td>-170.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.135784</td>\n",
       "      <td>2.049331</td>\n",
       "      <td>1.408328</td>\n",
       "      <td>0.962735</td>\n",
       "      <td>0.573144</td>\n",
       "      <td>0.806384</td>\n",
       "      <td>0.459228</td>\n",
       "      <td>0.286024</td>\n",
       "      <td>0.460434</td>\n",
       "      <td>0.645101</td>\n",
       "      <td>1.083966</td>\n",
       "      <td>1.188695</td>\n",
       "      <td>4557.5175</td>\n",
       "      <td>-7200.2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.342013</td>\n",
       "      <td>-0.482140</td>\n",
       "      <td>1.066643</td>\n",
       "      <td>0.689938</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.511391</td>\n",
       "      <td>0.126919</td>\n",
       "      <td>0.192025</td>\n",
       "      <td>0.316376</td>\n",
       "      <td>1.096034</td>\n",
       "      <td>1.604125</td>\n",
       "      <td>0.906979</td>\n",
       "      <td>4680.0961</td>\n",
       "      <td>-7837.7761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2021</td>\n",
       "      <td>-0.091628</td>\n",
       "      <td>0.142655</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>0.516358</td>\n",
       "      <td>0.406001</td>\n",
       "      <td>0.367842</td>\n",
       "      <td>0.027391</td>\n",
       "      <td>-0.134712</td>\n",
       "      <td>-0.227872</td>\n",
       "      <td>0.125336</td>\n",
       "      <td>-0.289356</td>\n",
       "      <td>0.369430</td>\n",
       "      <td>4156.4822</td>\n",
       "      <td>-6580.6955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2022</td>\n",
       "      <td>-0.240407</td>\n",
       "      <td>0.399310</td>\n",
       "      <td>1.343421</td>\n",
       "      <td>1.014020</td>\n",
       "      <td>0.660359</td>\n",
       "      <td>0.337941</td>\n",
       "      <td>-0.078175</td>\n",
       "      <td>-0.048633</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>0.397561</td>\n",
       "      <td>0.735196</td>\n",
       "      <td>1.568744</td>\n",
       "      <td>4417.7875</td>\n",
       "      <td>-7535.8186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.114168</td>\n",
       "      <td>0.200544</td>\n",
       "      <td>0.716625</td>\n",
       "      <td>-0.132468</td>\n",
       "      <td>0.165056</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.329172</td>\n",
       "      <td>0.169216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4487.4075</td>\n",
       "      <td>-7373.5186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year   Month_1   Month_2   Month_3   Month_4   Month_5   Month_6  \\\n",
       "0    1839  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    1840 -0.023147  0.018797 -0.005059  0.004945  0.000136  0.001689   \n",
       "2    1841 -0.007719 -0.022144 -0.041254  0.013252 -0.007577 -0.002464   \n",
       "3    1842 -0.051627 -0.064865  0.000281 -0.014042 -0.012324 -0.014331   \n",
       "4    1843 -0.068241 -0.019770  0.007994 -0.010482 -0.005797 -0.004244   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "150  2019 -0.135784  2.049331  1.408328  0.962735  0.573144  0.806384   \n",
       "151  2020 -0.342013 -0.482140  1.066643  0.689938  0.501524  0.511391   \n",
       "152  2021 -0.091628  0.142655  0.069941  0.516358  0.406001  0.367842   \n",
       "153  2022 -0.240407  0.399310  1.343421  1.014020  0.660359  0.337941   \n",
       "154  2023  0.114168  0.200544  0.716625 -0.132468  0.165056  0.101954   \n",
       "\n",
       "      Month_7   Month_8   Month_9  Month_10  Month_11  Month_12   Latitude  \\\n",
       "0    0.000000  0.014430  0.007909  0.008006 -0.006398 -0.017866    57.1553   \n",
       "1    0.007981 -0.000403 -0.002771 -0.008608 -0.021232 -0.050500    57.1553   \n",
       "2    0.003234 -0.001590 -0.000991 -0.009201 -0.017079 -0.029733    57.1553   \n",
       "3   -0.007447 -0.009897 -0.006924 -0.006234 -0.004618 -0.011339    57.1553   \n",
       "4   -0.000920 -0.003370 -0.000991  0.005633 -0.006398 -0.024393    57.1553   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "150  0.459228  0.286024  0.460434  0.645101  1.083966  1.188695  4557.5175   \n",
       "151  0.126919  0.192025  0.316376  1.096034  1.604125  0.906979  4680.0961   \n",
       "152  0.027391 -0.134712 -0.227872  0.125336 -0.289356  0.369430  4156.4822   \n",
       "153 -0.078175 -0.048633  0.312697  0.397561  0.735196  1.568744  4417.7875   \n",
       "154  0.329172  0.169216  0.000000  0.000000  0.000000  0.000000  4487.4075   \n",
       "\n",
       "     Longitude  \n",
       "0    -170.2222  \n",
       "1    -170.2222  \n",
       "2    -170.2222  \n",
       "3    -170.2222  \n",
       "4    -170.2222  \n",
       "..         ...  \n",
       "150 -7200.2425  \n",
       "151 -7837.7761  \n",
       "152 -6580.6955  \n",
       "153 -7535.8186  \n",
       "154 -7373.5186  \n",
       "\n",
       "[155 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_8000[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1216a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.800000</td>\n",
       "      <td>-94.000000</td>\n",
       "      <td>19.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.800000</td>\n",
       "      <td>-94.000000</td>\n",
       "      <td>19.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-92.300000</td>\n",
       "      <td>16.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-92.300000</td>\n",
       "      <td>16.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-92.300000</td>\n",
       "      <td>16.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.345431</td>\n",
       "      <td>1.344424</td>\n",
       "      <td>1.635074</td>\n",
       "      <td>0.443227</td>\n",
       "      <td>0.679776</td>\n",
       "      <td>0.457883</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>0.229139</td>\n",
       "      <td>0.642497</td>\n",
       "      <td>1.015959</td>\n",
       "      <td>0.985077</td>\n",
       "      <td>0.833929</td>\n",
       "      <td>5862.814260</td>\n",
       "      <td>-11824.209318</td>\n",
       "      <td>49.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.115655</td>\n",
       "      <td>-0.115044</td>\n",
       "      <td>0.514768</td>\n",
       "      <td>0.682888</td>\n",
       "      <td>0.310074</td>\n",
       "      <td>0.432401</td>\n",
       "      <td>0.147068</td>\n",
       "      <td>0.223943</td>\n",
       "      <td>0.322784</td>\n",
       "      <td>0.781347</td>\n",
       "      <td>0.727376</td>\n",
       "      <td>0.799195</td>\n",
       "      <td>5941.512516</td>\n",
       "      <td>-12080.216248</td>\n",
       "      <td>49.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.830500</td>\n",
       "      <td>0.158195</td>\n",
       "      <td>0.360250</td>\n",
       "      <td>0.583310</td>\n",
       "      <td>0.251487</td>\n",
       "      <td>0.349771</td>\n",
       "      <td>0.114235</td>\n",
       "      <td>0.026406</td>\n",
       "      <td>0.286828</td>\n",
       "      <td>1.135181</td>\n",
       "      <td>0.414355</td>\n",
       "      <td>0.514596</td>\n",
       "      <td>5764.728961</td>\n",
       "      <td>-11551.189734</td>\n",
       "      <td>49.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.227836</td>\n",
       "      <td>0.222603</td>\n",
       "      <td>1.029208</td>\n",
       "      <td>0.347086</td>\n",
       "      <td>0.373229</td>\n",
       "      <td>0.313193</td>\n",
       "      <td>0.247147</td>\n",
       "      <td>0.236943</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>0.638332</td>\n",
       "      <td>0.605486</td>\n",
       "      <td>0.911472</td>\n",
       "      <td>5829.024889</td>\n",
       "      <td>-11755.593016</td>\n",
       "      <td>49.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.555383</td>\n",
       "      <td>0.128828</td>\n",
       "      <td>1.011448</td>\n",
       "      <td>0.052302</td>\n",
       "      <td>0.525034</td>\n",
       "      <td>0.319974</td>\n",
       "      <td>0.618749</td>\n",
       "      <td>0.419689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5682.319039</td>\n",
       "      <td>-11439.545261</td>\n",
       "      <td>49.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year   Month_1   Month_2   Month_3   Month_4   Month_5   Month_6  \\\n",
       "0    1768  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    1769  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2    1774  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3    1775  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4    1776  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "220  2019  0.345431  1.344424  1.635074  0.443227  0.679776  0.457883   \n",
       "221  2020 -0.115655 -0.115044  0.514768  0.682888  0.310074  0.432401   \n",
       "222  2021  0.830500  0.158195  0.360250  0.583310  0.251487  0.349771   \n",
       "223  2022  0.227836  0.222603  1.029208  0.347086  0.373229  0.313193   \n",
       "224  2023  0.555383  0.128828  1.011448  0.052302  0.525034  0.319974   \n",
       "\n",
       "      Month_7   Month_8   Month_9  Month_10  Month_11  Month_12     Latitude  \\\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    58.800000   \n",
       "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    58.800000   \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    57.000000   \n",
       "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    57.000000   \n",
       "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    57.000000   \n",
       "..        ...       ...       ...       ...       ...       ...          ...   \n",
       "220  0.308756  0.229139  0.642497  1.015959  0.985077  0.833929  5862.814260   \n",
       "221  0.147068  0.223943  0.322784  0.781347  0.727376  0.799195  5941.512516   \n",
       "222  0.114235  0.026406  0.286828  1.135181  0.414355  0.514596  5764.728961   \n",
       "223  0.247147  0.236943  0.455133  0.638332  0.605486  0.911472  5829.024889   \n",
       "224  0.618749  0.419689  0.000000  0.000000  0.000000  0.000000  5682.319039   \n",
       "\n",
       "        Longitude     Source  \n",
       "0      -94.000000  19.625000  \n",
       "1      -94.000000  19.625000  \n",
       "2      -92.300000  16.600000  \n",
       "3      -92.300000  16.600000  \n",
       "4      -92.300000  16.600000  \n",
       "..            ...        ...  \n",
       "220 -11824.209318  49.090909  \n",
       "221 -12080.216248  49.090909  \n",
       "222 -11551.189734  49.090909  \n",
       "223 -11755.593016  49.090909  \n",
       "224 -11439.545261  49.090909  \n",
       "\n",
       "[225 rows x 16 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_80[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529dbe56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
