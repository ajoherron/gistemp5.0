{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a0545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import itertools\n",
    "import math\n",
    "from io import StringIO\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013b1a4",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4577507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 0: Downloading Data\n",
    "\n",
    "Combining diverse inputs into a single dataset\n",
    "\n",
    "Inputs include:\n",
    "    - GHCN v4 data\n",
    "    - ERRST v5 data (later on?)\n",
    "'''\n",
    "\n",
    "# Standard library imports\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add the parent folder to sys.path\n",
    "# parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Local imports\n",
    "# from parameters.data import GHCN_temp_url, GHCN_meta_url\n",
    "GHCN_temp_url = 'https://data.giss.nasa.gov/pub/gistemp/ghcnm.tavg.qcf.dat'\n",
    "GHCN_meta_url = 'https://data.giss.nasa.gov/pub/gistemp/v4.inv'\n",
    "\n",
    "# Local imports\n",
    "from parameters.data import GHCN_temp_url, GHCN_meta_url\n",
    "\n",
    "def get_GHCN_data(temp_url: str, meta_url: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Retrieves and formats temperature data from the Global Historical Climatology Network (GHCN) dataset.\n",
    "\n",
    "    Args:\n",
    "    temp_url (str): The URL to the temperature data file in GHCN format.\n",
    "    meta_url (str): The URL to the metadata file containing station information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing temperature data with station metadata.\n",
    "    \n",
    "    This function sends an HTTP GET request to the temperature data URL, processes the data to create\n",
    "    a formatted DataFrame, replaces missing values with NaN, converts temperature values to degrees Celsius,\n",
    "    and merges the data with station metadata based on station IDs. The resulting DataFrame includes\n",
    "    columns for station latitude, longitude, and name, and is indexed by station IDs.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(temp_url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            \n",
    "            # Get the content of the response\n",
    "            file_data: str = response.content.decode(\"utf-8\")\n",
    "\n",
    "            # Create a list to store formatted data\n",
    "            formatted_data = []\n",
    "\n",
    "            # Loop through file data\n",
    "            for line in file_data.split('\\n'):\n",
    "                \n",
    "                # Check if line is not empty\n",
    "                if line.strip():\n",
    "                    \n",
    "                    # Extract relevant data\n",
    "                    # (Using code from GHCNV4Reader())\n",
    "                    station_id: str = line[:11]\n",
    "                    year: int = int(line[11:15])\n",
    "                    values: List[int] = [int(line[i:i+5]) for i in range(19, 115, 8)]\n",
    "                    \n",
    "                    # Append data to list\n",
    "                    formatted_data.append([station_id, year] + values)\n",
    "\n",
    "            # Create DataFrame from formatted data\n",
    "            column_names: List[str] = ['Station_ID', 'Year'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN: pd.DataFrame = pd.DataFrame(formatted_data, columns=column_names)\n",
    "            \n",
    "            # Replace -9999 with NaN\n",
    "            df_GHCN.replace(-9999, np.nan, inplace=True)\n",
    "            \n",
    "            # Format data - convert to degrees C\n",
    "            month_columns: List[str] = [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN[month_columns] = df_GHCN[month_columns].divide(100)\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    # Define the column widths, create meta data dataframe\n",
    "    column_widths: List[int] = [11, 9, 10, 7, 3, 31]\n",
    "    df_meta: pd.DataFrame = pd.read_fwf(meta_url, widths=column_widths, header=None,\n",
    "                          names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])\n",
    "    # Merge on station ID, set index\n",
    "    df: pd.DataFrame = pd.merge(df_GHCN, df_meta[['Station_ID', 'Latitude', 'Longitude', 'Name']], on='Station_ID', how='left')\n",
    "    df = df.set_index('Station_ID')\n",
    "\n",
    "    return df\n",
    "\n",
    "def step0() -> pd.DataFrame:\n",
    "    '''\n",
    "    Performs the initial data processing steps for the GHCN temperature dataset.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing filtered and formatted temperature data.\n",
    "    \n",
    "    This function retrieves temperature data from the Global Historical Climatology Network (GHCN) dataset,\n",
    "    processes and formats the data, and returns a DataFrame. The data is first fetched using specified URLs,\n",
    "    and is returned for further analysis.\n",
    "    '''\n",
    "    df_GHCN: pd.DataFrame = get_GHCN_data(GHCN_temp_url, GHCN_meta_url)\n",
    "    return df_GHCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c396e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "step0_output = step0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad6e23",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b065356",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1: Removal of bad data\n",
    "\n",
    "Drop or adjust certain records (or parts of records).\n",
    "This includes outliers / out of range reports.\n",
    "Determined using configuration file.\n",
    "    <TO-DO> Figure out if this method is ideal.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Add the parent folder to sys.path\n",
    "# parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Local imports\n",
    "# from parameters.data import drop_rules\n",
    "drop_rules = '''\n",
    "CHM00052836  omit: 0-1948\n",
    "CHXLT909860  omit: 0-1950\n",
    "BL000085365  omit: 0-1930\n",
    "MXXLT948335  omit: 0-1952\n",
    "ASN00058012  omit: 0-1899\n",
    "ASN00084016  omit: 0-1899\n",
    "ASN00069018  omit: 0-1898\n",
    "NIXLT013080  omit: 0-1930\n",
    "NIXLT751359  omit: 0-9999\n",
    "CHXLT063941  omit: 0-1937\n",
    "CHM00054843  omit: 0-1937\n",
    "MXM00076373  omit: 0-9999\n",
    "USC00044022  omit: 0-9999\n",
    "USC00044025  omit: 0-9999\n",
    "CA002402332  omit: 2011-9999\n",
    "RSM00024266  omit: 2021/09\n",
    "'''\n",
    "\n",
    "\n",
    "def filter_coordinates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters a DataFrame based on latitude and longitude conditions.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame with rows where latitude is between -90 and 90,\n",
    "    and longitude is between -180 and 180.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define latitude and longitude range conditions\n",
    "    lat_condition = (df['Latitude'] >= -90) & (df['Latitude'] <= 90)\n",
    "    lon_condition = (df['Longitude'] >= -180) & (df['Longitude'] <= 180)\n",
    "\n",
    "    # Apply the conditions to filter the DataFrame\n",
    "    df_filtered = df[lat_condition & lon_condition]\n",
    "    \n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(df) - len(df_filtered)\n",
    "    print(f'Number of rows with invalid coordinates (removed): {num_filtered}')\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def filter_stations_by_rules(dataframe: pd.DataFrame, rules_text: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters a DataFrame of climate station data based on exclusion rules specified in a text format.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing climate station data.\n",
    "        rules_text (str): A string containing exclusion rules for specific stations and years.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame with stations omitted based on the provided rules.\n",
    "\n",
    "    Rules Format:\n",
    "        The 'rules_text' should be formatted as follows:\n",
    "        - Each rule is represented as a single line in the text.\n",
    "        - Each line should start with the station ID followed by exclusion rules.\n",
    "        - Exclusion rules consist of 'omit:' followed by the years to exclude, e.g., 'omit: 2000-2010'.\n",
    "        - Years can be specified as a single year (e.g., 'omit: 2000') or as a range (e.g., 'omit: 2000-2010').\n",
    "        - Year ranges can also be specified using '/' (e.g., 'omit: 2000/2002').\n",
    "\n",
    "    Example:\n",
    "        rules_text = '''\n",
    "            CHM00052836  omit: 0-1948\n",
    "            CHXLT909860  omit: 0-1950\n",
    "            BL000085365  omit: 0-1930\n",
    "            ...\n",
    "        '''\n",
    "\n",
    "    This function takes the provided rules and applies them to the input DataFrame,\n",
    "    resulting in a new DataFrame with stations excluded based on the specified rules.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the rules from the provided text\n",
    "    rules = {}\n",
    "    for line in rules_text.split('\\n'):\n",
    "        if line.strip():\n",
    "            match = re.match(r'([A-Z0-9]+)\\s+omit:\\s+(\\S+)', line)\n",
    "            if match:\n",
    "                station_id, year_rule = match.groups()\n",
    "                rules[station_id] = year_rule\n",
    "\n",
    "    # Create a mask to identify rows to omit\n",
    "    mask = pd.Series(True, index=dataframe.index)\n",
    "\n",
    "    for station_id, year_rule in rules.items():\n",
    "        try:\n",
    "            # Split the year_rule into start and end years\n",
    "            start_year, end_year = map(int, year_rule.split('-'))\n",
    "        except ValueError:\n",
    "            # Handle cases like '2011/12' or '2012-9999'\n",
    "            if '/' in year_rule:\n",
    "                start_year = int(year_rule.split('/')[0])\n",
    "                end_year = start_year\n",
    "            elif '-' in year_rule:\n",
    "                start_year = int(year_rule.split('-')[0])\n",
    "                end_year = int(year_rule.split('-')[1])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Update the mask to False for the specified range of years for the station_id\n",
    "        mask &= ~((dataframe['Year'] >= start_year) & (dataframe['Year'] <= end_year) & (dataframe.index == station_id))\n",
    "\n",
    "    # Apply the mask to filter the DataFrame\n",
    "    filtered_dataframe = dataframe[mask]\n",
    "\n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(dataframe) - len(filtered_dataframe)\n",
    "    print(f'Number of rows removed according to station exclusion rules: {num_filtered}')\n",
    "\n",
    "    return filtered_dataframe\n",
    "\n",
    "def step1(step0_output: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies data filtering and cleaning operations to the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        step0_output (pd.DataFrame): The initial DataFrame containing climate station data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned and filtered DataFrame ready for further analysis.\n",
    "\n",
    "    This function serves as a data processing step by applying two essential filtering operations:\n",
    "    1. `filter_coordinates`: Filters the DataFrame based on geographical coordinates, retaining relevant stations.\n",
    "    2. `filter_stations_by_rules`: Filters the DataFrame based on exclusion rules, omitting specified stations and years.\n",
    "\n",
    "    The resulting DataFrame is cleaned of irrelevant stations and years according to specified rules\n",
    "    and is ready for subsequent data analysis or visualization.\n",
    "    \"\"\"\n",
    "        \n",
    "    df_filtered = filter_coordinates(step0_output)\n",
    "    df_clean = filter_stations_by_rules(df_filtered, drop_rules)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15764ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid coordinates (removed): 0\n",
      "Number of rows removed according to station exclusion rules: 524\n"
     ]
    }
   ],
   "source": [
    "step1_output = step1(step0_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6004502",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39fb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0e24b",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1fa621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 3: Gridding of cells\n",
    "\n",
    "There are 8000 cells across the globe.\n",
    "Each cell's values are computed using station records within a 1200km radius.\n",
    "    - Contributions are weighted according to distance to cell center\n",
    "    (linearly decreasing to 0 at distance 1200km)\n",
    "'''\n",
    "\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "\n",
    "def calculate_area(row: Series) -> float:\n",
    "    earth_radius_km: float = 6371.0\n",
    "    delta_longitude: float = np.radians(row['Eastern'] - row['Western'])\n",
    "    southern_latitude: float = np.radians(row['Southern'])\n",
    "    northern_latitude: float = np.radians(row['Northern'])\n",
    "    area: float = (earth_radius_km ** 2) * delta_longitude * (np.sin(northern_latitude) - np.sin(southern_latitude))\n",
    "    return area\n",
    "\n",
    "\n",
    "def calculate_center_coordinates(row: pd.Series) -> Tuple[float, float]:\n",
    "    \"\"\"Calculate the center latitude and longitude for a given box.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A Pandas Series representing a row of the DataFrame with ('southern', 'northern', 'western', 'eastern') coordinates.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple containing the center latitude and longitude.\n",
    "    \"\"\"\n",
    "    center_latitude = 0.5 * (math.sin(row['Southern'] * math.pi / 180) + math.sin(row['Northern'] * math.pi / 180))\n",
    "    center_longitude = 0.5 * (row['Western'] + row['Eastern'])\n",
    "    center_latitude = math.asin(center_latitude) * 180 / math.pi\n",
    "    return center_latitude, center_longitude\n",
    "\n",
    "\n",
    "def generate_80_cell_grid() -> pd.DataFrame:\n",
    "    \"\"\"Generate an 80-cell grid DataFrame with columns for southern, northern, western, eastern,\n",
    "    center_latitude, and center_longitude coordinates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The generated DataFrame.\n",
    "    \"\"\"\n",
    "    grid_data = []\n",
    "    \n",
    "    # Number of horizontal boxes in each band\n",
    "    # (proportional to the thickness of each band)\n",
    "    band_boxes = [4, 8, 12, 16]\n",
    "    \n",
    "    # Sines of latitudes\n",
    "    band_altitude = [1, 0.9, 0.7, 0.4, 0]\n",
    "\n",
    "    # Generate the 40 cells in the northern hemisphere\n",
    "    for band in range(len(band_boxes)):\n",
    "        n = band_boxes[band]\n",
    "        for i in range(n):\n",
    "            lats = 180 / math.pi * math.asin(band_altitude[band + 1])\n",
    "            latn = 180 / math.pi * math.asin(band_altitude[band])\n",
    "            lonw = -180 + 360 * float(i) / n\n",
    "            lone = -180 + 360 * float(i + 1) / n\n",
    "            box = (lats, latn, lonw, lone)\n",
    "            grid_data.append(box)\n",
    "\n",
    "    # Generate the 40 cells in the southern hemisphere by reversing the northern hemisphere cells\n",
    "    for box in grid_data[::-1]:\n",
    "        grid_data.append((-box[1], -box[0], box[2], box[3]))\n",
    "\n",
    "    # Create a DataFrame from the grid data\n",
    "    df = pd.DataFrame(grid_data, columns=['Southern', 'Northern', 'Western', 'Eastern'])\n",
    "\n",
    "    # Calculate center coordinates for each box and add them as new columns\n",
    "    center_coords = df.apply(calculate_center_coordinates, axis=1)\n",
    "    df[['Center_Latitude', 'Center_Longitude']] = pd.DataFrame(center_coords.tolist(), index=df.index)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def interpolate(x: float, y: float, p: float) -> float:\n",
    "    return y * p + (1 - p) * x\n",
    "\n",
    "\n",
    "def generate_8000_cell_grid(grid_80):\n",
    "\n",
    "    # Initialize an empty list to store subboxes\n",
    "    subbox_list = []\n",
    "\n",
    "    for index, row in grid_80.iterrows():\n",
    "        alts = math.sin(row['Southern'] * math.pi / 180)\n",
    "        altn = math.sin(row['Northern'] * math.pi / 180)\n",
    "\n",
    "        for y in range(10):\n",
    "            s = 180 * math.asin(interpolate(alts, altn, y * 0.1)) / math.pi\n",
    "            n = 180 * math.asin(interpolate(alts, altn, (y + 1) * 0.1)) / math.pi\n",
    "            for x in range(10):\n",
    "                w = interpolate(row['Western'], row['Eastern'], x * 0.1)\n",
    "                e = interpolate(row['Western'], row['Eastern'], (x + 1) * 0.1)\n",
    "\n",
    "                # Create a DataFrame for the subbox\n",
    "                subbox_df = pd.DataFrame({'Southern': [s], 'Northern': [n], 'Western': [w], 'Eastern': [e]})\n",
    "\n",
    "                # Append the subbox DataFrame to the list\n",
    "                subbox_list.append(subbox_df)\n",
    "\n",
    "    # Concatenate all subboxes into a single DataFrame\n",
    "    grid_8000 = pd.concat(subbox_list, ignore_index=True)\n",
    "\n",
    "    # Calculate center coordinates for each box and add them as new columns\n",
    "    center_coords = grid_8000.apply(calculate_center_coordinates, axis=1)\n",
    "    grid_8000[['Center_Latitude', 'Center_Longitude']] = pd.DataFrame(center_coords.tolist(), index=grid_8000.index)\n",
    "\n",
    "    # Calculate area of all 8000 cells\n",
    "    grid_8000['Area'] = grid_8000.apply(calculate_area, axis=1)\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    return grid_8000\n",
    "\n",
    "def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the spherical distance (in kilometers) between two pairs of\n",
    "    latitude and longitude coordinates using the Haversine formula.\n",
    "\n",
    "    Args:\n",
    "        lat1 (float): Latitude of the first point in degrees.\n",
    "        lon1 (float): Longitude of the first point in degrees.\n",
    "        lat2 (float): Latitude of the second point in degrees.\n",
    "        lon2 (float): Longitude of the second point in degrees.\n",
    "\n",
    "    Returns:\n",
    "        float: Spherical distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    # Radius of the Earth in kilometers\n",
    "    radius: float = 6371.0  # Earth's mean radius\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat: float = lat2 - lat1\n",
    "    dlon: float = lon2 - lon1\n",
    "\n",
    "    a: float = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c: float = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    distance: float = radius * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def linearly_decreasing_weight(distance: float, max_distance: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate a linearly decreasing weight based on the given distance\n",
    "    and maximum distance.\n",
    "\n",
    "    Args:\n",
    "        distance (float): The distance at which you want to calculate the weight.\n",
    "        max_distance (float): The maximum distance at which the weight becomes 0.\n",
    "\n",
    "    Returns:\n",
    "        float: The linearly decreasing weight, ranging from 1 to 0.\n",
    "    \"\"\"\n",
    "    # Ensure that distance is within the valid range [0, max_distance]\n",
    "    distance: float = max(0, min(distance, max_distance))\n",
    "\n",
    "    # Calculate the weight as a linear interpolation\n",
    "    weight: float = 1.0 - (distance / max_distance)\n",
    "    \n",
    "    return weight\n",
    "\n",
    "def nearby_stations(grid_df):\n",
    "\n",
    "    # Initialize an empty list to store station IDs and weights as dictionaries\n",
    "    station_weights_within_radius = []\n",
    "\n",
    "    # Maximum distance for the weight calculation (e.g., 1200.0 km)\n",
    "    max_distance = 1200.0\n",
    "\n",
    "    # Use tqdm to track progress\n",
    "    for index, row in tqdm(grid_df.iterrows(), total=len(grid_df), desc=\"Processing\"):\n",
    "        center_lat = row['Center_Latitude']\n",
    "        center_lon = row['Center_Longitude']\n",
    "\n",
    "        # Calculate distances for each station in station_df\n",
    "        distances = station_df.apply(lambda x: haversine_distance(center_lat, center_lon, x['Latitude'], x['Longitude']), axis=1)\n",
    "\n",
    "        # Find station IDs within the specified radius\n",
    "        nearby_stations = station_df[distances <= max_distance]\n",
    "\n",
    "        # Calculate weights for each nearby station\n",
    "        weights = nearby_stations.apply(lambda x: linearly_decreasing_weight(distances[x.name], max_distance), axis=1)\n",
    "\n",
    "        # Create a dictionary of station IDs and weights\n",
    "        station_weights = dict(zip(nearby_stations['Station_ID'], weights))\n",
    "\n",
    "        # Append the dictionary to the result list\n",
    "        station_weights_within_radius.append(station_weights)\n",
    "\n",
    "    # Add the list of station IDs and weights as a new column\n",
    "    grid_df['Nearby_Stations'] = station_weights_within_radius\n",
    "\n",
    "    # Set index name\n",
    "    grid_df.index.name = 'Box_Number'\n",
    "    \n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8daf774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_80 = generate_80_cell_grid()\n",
    "grid_80['Area'] = grid_80.apply(calculate_area, axis=1)\n",
    "\n",
    "grid_8000 = generate_8000_cell_grid(grid_80)\n",
    "grid_8000['Area'] = grid_8000.apply(calculate_area, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1e44c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_url = 'https://data.giss.nasa.gov/pub/gistemp/v4.inv'\n",
    "column_widths: List[int] = [11, 9, 10, 7, 3, 31]\n",
    "station_df: pd.DataFrame = pd.read_fwf(meta_url, widths=column_widths, header=None,\n",
    "                          names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43b0c382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████████████████| 80/80 [00:06<00:00, 12.41it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_80 = nearby_stations(grid_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eca38ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████████████| 8000/8000 [10:41<00:00, 12.48it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_8000 = nearby_stations(grid_8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "548ab494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Southern</th>\n",
       "      <th>Northern</th>\n",
       "      <th>Western</th>\n",
       "      <th>Eastern</th>\n",
       "      <th>Center_Latitude</th>\n",
       "      <th>Center_Longitude</th>\n",
       "      <th>Area</th>\n",
       "      <th>Nearby_Stations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Box_Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.158067</td>\n",
       "      <td>65.505352</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>64.823283</td>\n",
       "      <td>-175.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'RSM00021965': 0.06629837649322723, 'RSM00021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.158067</td>\n",
       "      <td>65.505352</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>64.823283</td>\n",
       "      <td>-166.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'CA002100697': 0.003362114448123288, 'RSM0002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.158067</td>\n",
       "      <td>65.505352</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>64.823283</td>\n",
       "      <td>-157.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'CA002100100': 0.11900842694943892, 'CA002100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.158067</td>\n",
       "      <td>65.505352</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>64.823283</td>\n",
       "      <td>-148.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'CA001191440': 0.045975337634871716, 'CA00119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.158067</td>\n",
       "      <td>65.505352</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>64.823283</td>\n",
       "      <td>-139.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'CA001060330': 0.03890593070854176, 'CA001060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>-65.505352</td>\n",
       "      <td>-64.158067</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-64.823283</td>\n",
       "      <td>-130.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'AYM00089327': 0.21571371266640837, 'XXXLT848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>-65.505352</td>\n",
       "      <td>-64.158067</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>-64.823283</td>\n",
       "      <td>-121.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'AYM00089327': 0.20306151170328113, 'XXXLT848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>-65.505352</td>\n",
       "      <td>-64.158067</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>-108.0</td>\n",
       "      <td>-64.823283</td>\n",
       "      <td>-112.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'AYM00089327': 0.09129442167304602, 'XXXLT848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>-65.505352</td>\n",
       "      <td>-64.158067</td>\n",
       "      <td>-108.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-64.823283</td>\n",
       "      <td>-103.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'XXXLT848602': 0.688391524962565}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-65.505352</td>\n",
       "      <td>-64.158067</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-64.823283</td>\n",
       "      <td>-94.5</td>\n",
       "      <td>63758.058989</td>\n",
       "      <td>{'AYXLT606419': 0.015936825823877343, 'XXXLT84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Southern   Northern  Western  Eastern  Center_Latitude  \\\n",
       "Box_Number                                                            \n",
       "0           64.158067  65.505352   -180.0   -171.0        64.823283   \n",
       "1           64.158067  65.505352   -171.0   -162.0        64.823283   \n",
       "2           64.158067  65.505352   -162.0   -153.0        64.823283   \n",
       "3           64.158067  65.505352   -153.0   -144.0        64.823283   \n",
       "4           64.158067  65.505352   -144.0   -135.0        64.823283   \n",
       "...               ...        ...      ...      ...              ...   \n",
       "7995       -65.505352 -64.158067   -135.0   -126.0       -64.823283   \n",
       "7996       -65.505352 -64.158067   -126.0   -117.0       -64.823283   \n",
       "7997       -65.505352 -64.158067   -117.0   -108.0       -64.823283   \n",
       "7998       -65.505352 -64.158067   -108.0    -99.0       -64.823283   \n",
       "7999       -65.505352 -64.158067    -99.0    -90.0       -64.823283   \n",
       "\n",
       "            Center_Longitude          Area  \\\n",
       "Box_Number                                   \n",
       "0                     -175.5  63758.058989   \n",
       "1                     -166.5  63758.058989   \n",
       "2                     -157.5  63758.058989   \n",
       "3                     -148.5  63758.058989   \n",
       "4                     -139.5  63758.058989   \n",
       "...                      ...           ...   \n",
       "7995                  -130.5  63758.058989   \n",
       "7996                  -121.5  63758.058989   \n",
       "7997                  -112.5  63758.058989   \n",
       "7998                  -103.5  63758.058989   \n",
       "7999                   -94.5  63758.058989   \n",
       "\n",
       "                                              Nearby_Stations  \n",
       "Box_Number                                                     \n",
       "0           {'RSM00021965': 0.06629837649322723, 'RSM00021...  \n",
       "1           {'CA002100697': 0.003362114448123288, 'RSM0002...  \n",
       "2           {'CA002100100': 0.11900842694943892, 'CA002100...  \n",
       "3           {'CA001191440': 0.045975337634871716, 'CA00119...  \n",
       "4           {'CA001060330': 0.03890593070854176, 'CA001060...  \n",
       "...                                                       ...  \n",
       "7995        {'AYM00089327': 0.21571371266640837, 'XXXLT848...  \n",
       "7996        {'AYM00089327': 0.20306151170328113, 'XXXLT848...  \n",
       "7997        {'AYM00089327': 0.09129442167304602, 'XXXLT848...  \n",
       "7998                       {'XXXLT848602': 0.688391524962565}  \n",
       "7999        {'AYXLT606419': 0.015936825823877343, 'XXXLT84...  \n",
       "\n",
       "[8000 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807d03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1631c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b558ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3c5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df56435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f259986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_box_number(station_df, grid_80_df):\n",
    "    box_numbers = []\n",
    "\n",
    "    for _, station_row in tqdm(station_df.iterrows(), total=len(station_df)):\n",
    "        latitude = station_row['Latitude']\n",
    "        longitude = station_row['Longitude']\n",
    "\n",
    "        for box_number, box_row in grid_80_df.iterrows():\n",
    "            southern = box_row['Southern']\n",
    "            northern = box_row['Northern']\n",
    "            western = box_row['Western']\n",
    "            eastern = box_row['Eastern']\n",
    "\n",
    "            if southern <= latitude <= northern and western <= longitude <= eastern:\n",
    "                box_numbers.append(box_number)\n",
    "                break\n",
    "        else:\n",
    "            box_numbers.append(None)\n",
    "\n",
    "    return box_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e896722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 124954/124954 [01:19<00:00, 1570.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find box numbers for each station, add to station_df\n",
    "box_numbers = find_box_number(station_df, grid_80_df)\n",
    "station_df['Box_Number'] = box_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b34d2e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>State</th>\n",
       "      <th>Name</th>\n",
       "      <th>Box_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>10.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DUBAI INTL</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>26.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124949</th>\n",
       "      <td>ZI000067969</td>\n",
       "      <td>-21.0500</td>\n",
       "      <td>29.3670</td>\n",
       "      <td>861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WEST NICHOLSON</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124950</th>\n",
       "      <td>ZI000067975</td>\n",
       "      <td>-20.0670</td>\n",
       "      <td>30.8670</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASVINGO</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124951</th>\n",
       "      <td>ZI000067977</td>\n",
       "      <td>-21.0170</td>\n",
       "      <td>31.5830</td>\n",
       "      <td>430.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUFFALO RANGE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124952</th>\n",
       "      <td>ZI000067983</td>\n",
       "      <td>-20.2000</td>\n",
       "      <td>32.6160</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHIPINGE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124953</th>\n",
       "      <td>ZI000067991</td>\n",
       "      <td>-22.2170</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BEITBRIDGE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124954 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Station_ID  Latitude  Longitude  Elevation State  \\\n",
       "0       ACW00011604   17.1167   -61.7833       10.1   NaN   \n",
       "1       ACW00011647   17.1333   -61.7833       19.2   NaN   \n",
       "2       AE000041196   25.3330    55.5170       34.0   NaN   \n",
       "3       AEM00041194   25.2550    55.3640       10.4   NaN   \n",
       "4       AEM00041217   24.4330    54.6510       26.8   NaN   \n",
       "...             ...       ...        ...        ...   ...   \n",
       "124949  ZI000067969  -21.0500    29.3670      861.0   NaN   \n",
       "124950  ZI000067975  -20.0670    30.8670     1095.0   NaN   \n",
       "124951  ZI000067977  -21.0170    31.5830      430.0   NaN   \n",
       "124952  ZI000067983  -20.2000    32.6160     1132.0   NaN   \n",
       "124953  ZI000067991  -22.2170    30.0000      457.0   NaN   \n",
       "\n",
       "                         Name  Box_Number  \n",
       "0       ST JOHNS COOLIDGE FLD          43  \n",
       "1                    ST JOHNS          43  \n",
       "2         SHARJAH INTER. AIRP          56  \n",
       "3                  DUBAI INTL          56  \n",
       "4              ABU DHABI INTL          56  \n",
       "...                       ...         ...  \n",
       "124949         WEST NICHOLSON          35  \n",
       "124950               MASVINGO          35  \n",
       "124951          BUFFALO RANGE          35  \n",
       "124952               CHIPINGE          35  \n",
       "124953             BEITBRIDGE          35  \n",
       "\n",
       "[124954 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851c677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d68251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d50727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35197b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf406e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75d652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfc28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77402833",
   "metadata": {},
   "source": [
    "# Step 4: SST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f19a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53979c49",
   "metadata": {},
   "source": [
    "# Step 5: Anomalyzing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8bc6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalize_temperature_data(data, reference_period=(1951, 1980)):\n",
    "    # Extract the years from the DataFrame\n",
    "    years = data['Year'].unique()\n",
    "    \n",
    "    # Calculate monthly means for the reference period\n",
    "    reference_data = data[(data['Year'] >= reference_period[0]) & (data['Year'] <= reference_period[1])]\n",
    "    monthly_means = reference_data.iloc[:, 1:13].mean()\n",
    "    \n",
    "    # Initialize a DataFrame to store the anomalized data\n",
    "    anomalized_data = data.copy()\n",
    "    \n",
    "    # Anomalize each month's data\n",
    "    for month in tqdm(range(1, 13), desc=\"Anomalizing Months\"):\n",
    "        \n",
    "        # Calculate the anomaly for the current month\n",
    "        anomalized_data[f'Month_{month}'] = data.apply(lambda row: row[f'Month_{month}'] - monthly_means[month - 1], axis=1)\n",
    "    \n",
    "    return anomalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eac5d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anomalizing Months: 100%|███████████████████████| 12/12 [00:44<00:00,  3.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1961</td>\n",
       "      <td>-1.439347</td>\n",
       "      <td>0.135949</td>\n",
       "      <td>-1.07872</td>\n",
       "      <td>-2.841062</td>\n",
       "      <td>-3.591227</td>\n",
       "      <td>-2.476789</td>\n",
       "      <td>-4.786892</td>\n",
       "      <td>-5.059991</td>\n",
       "      <td>-2.578559</td>\n",
       "      <td>-0.337097</td>\n",
       "      <td>-1.52523</td>\n",
       "      <td>-2.780427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1962</td>\n",
       "      <td>0.580653</td>\n",
       "      <td>-1.374051</td>\n",
       "      <td>-7.33872</td>\n",
       "      <td>-4.221062</td>\n",
       "      <td>-5.791227</td>\n",
       "      <td>-4.656789</td>\n",
       "      <td>-5.386892</td>\n",
       "      <td>-5.939991</td>\n",
       "      <td>-5.078559</td>\n",
       "      <td>-2.137097</td>\n",
       "      <td>-3.39523</td>\n",
       "      <td>-3.650427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1963</td>\n",
       "      <td>-7.679347</td>\n",
       "      <td>-7.754051</td>\n",
       "      <td>-6.78872</td>\n",
       "      <td>-5.161062</td>\n",
       "      <td>-2.631227</td>\n",
       "      <td>-2.196789</td>\n",
       "      <td>-4.286892</td>\n",
       "      <td>-3.909991</td>\n",
       "      <td>-3.388559</td>\n",
       "      <td>-2.677097</td>\n",
       "      <td>-0.96523</td>\n",
       "      <td>-3.470427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1964</td>\n",
       "      <td>0.070653</td>\n",
       "      <td>-3.074051</td>\n",
       "      <td>-5.24872</td>\n",
       "      <td>-3.191062</td>\n",
       "      <td>-2.681227</td>\n",
       "      <td>-4.046789</td>\n",
       "      <td>-5.426892</td>\n",
       "      <td>-4.299991</td>\n",
       "      <td>-4.498559</td>\n",
       "      <td>-4.197097</td>\n",
       "      <td>-1.16523</td>\n",
       "      <td>-1.270427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1965</td>\n",
       "      <td>-0.109347</td>\n",
       "      <td>-3.274051</td>\n",
       "      <td>-5.41872</td>\n",
       "      <td>-4.671062</td>\n",
       "      <td>-5.001227</td>\n",
       "      <td>-3.466789</td>\n",
       "      <td>-5.616892</td>\n",
       "      <td>-5.099991</td>\n",
       "      <td>-2.938559</td>\n",
       "      <td>-2.337097</td>\n",
       "      <td>-6.31523</td>\n",
       "      <td>-4.170427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1966</td>\n",
       "      <td>21.290653</td>\n",
       "      <td>18.215949</td>\n",
       "      <td>12.64128</td>\n",
       "      <td>6.368938</td>\n",
       "      <td>-0.531227</td>\n",
       "      <td>-5.626789</td>\n",
       "      <td>-8.346892</td>\n",
       "      <td>-5.229991</td>\n",
       "      <td>1.031441</td>\n",
       "      <td>7.762903</td>\n",
       "      <td>14.31477</td>\n",
       "      <td>18.749573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1967</td>\n",
       "      <td>20.590653</td>\n",
       "      <td>17.715949</td>\n",
       "      <td>13.14128</td>\n",
       "      <td>8.668938</td>\n",
       "      <td>0.268773</td>\n",
       "      <td>-4.926789</td>\n",
       "      <td>-9.446892</td>\n",
       "      <td>-6.029991</td>\n",
       "      <td>-0.068559</td>\n",
       "      <td>8.762903</td>\n",
       "      <td>13.31477</td>\n",
       "      <td>16.749573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1968</td>\n",
       "      <td>21.290653</td>\n",
       "      <td>17.815949</td>\n",
       "      <td>13.54128</td>\n",
       "      <td>7.668938</td>\n",
       "      <td>0.768773</td>\n",
       "      <td>-7.626789</td>\n",
       "      <td>-6.746892</td>\n",
       "      <td>-3.529991</td>\n",
       "      <td>0.931441</td>\n",
       "      <td>9.762903</td>\n",
       "      <td>11.81477</td>\n",
       "      <td>18.349573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1969</td>\n",
       "      <td>20.390653</td>\n",
       "      <td>19.315949</td>\n",
       "      <td>13.74128</td>\n",
       "      <td>7.768938</td>\n",
       "      <td>-0.731227</td>\n",
       "      <td>-5.326789</td>\n",
       "      <td>-8.846892</td>\n",
       "      <td>-5.229991</td>\n",
       "      <td>1.131441</td>\n",
       "      <td>8.962903</td>\n",
       "      <td>13.81477</td>\n",
       "      <td>16.749573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1970</td>\n",
       "      <td>20.190653</td>\n",
       "      <td>17.715949</td>\n",
       "      <td>13.54128</td>\n",
       "      <td>6.668938</td>\n",
       "      <td>0.768773</td>\n",
       "      <td>-5.126789</td>\n",
       "      <td>-7.146892</td>\n",
       "      <td>-4.429991</td>\n",
       "      <td>3.731441</td>\n",
       "      <td>8.262903</td>\n",
       "      <td>14.71477</td>\n",
       "      <td>19.149573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1452682 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Year    Month_1    Month_2   Month_3   Month_4   Month_5  \\\n",
       "Station_ID                                                              \n",
       "ACW00011604  1961  -1.439347   0.135949  -1.07872 -2.841062 -3.591227   \n",
       "ACW00011604  1962   0.580653  -1.374051  -7.33872 -4.221062 -5.791227   \n",
       "ACW00011604  1963  -7.679347  -7.754051  -6.78872 -5.161062 -2.631227   \n",
       "ACW00011604  1964   0.070653  -3.074051  -5.24872 -3.191062 -2.681227   \n",
       "ACW00011604  1965  -0.109347  -3.274051  -5.41872 -4.671062 -5.001227   \n",
       "...           ...        ...        ...       ...       ...       ...   \n",
       "ZIXLT622116  1966  21.290653  18.215949  12.64128  6.368938 -0.531227   \n",
       "ZIXLT622116  1967  20.590653  17.715949  13.14128  8.668938  0.268773   \n",
       "ZIXLT622116  1968  21.290653  17.815949  13.54128  7.668938  0.768773   \n",
       "ZIXLT622116  1969  20.390653  19.315949  13.74128  7.768938 -0.731227   \n",
       "ZIXLT622116  1970  20.190653  17.715949  13.54128  6.668938  0.768773   \n",
       "\n",
       "              Month_6   Month_7   Month_8   Month_9  Month_10  Month_11  \\\n",
       "Station_ID                                                                \n",
       "ACW00011604 -2.476789 -4.786892 -5.059991 -2.578559 -0.337097  -1.52523   \n",
       "ACW00011604 -4.656789 -5.386892 -5.939991 -5.078559 -2.137097  -3.39523   \n",
       "ACW00011604 -2.196789 -4.286892 -3.909991 -3.388559 -2.677097  -0.96523   \n",
       "ACW00011604 -4.046789 -5.426892 -4.299991 -4.498559 -4.197097  -1.16523   \n",
       "ACW00011604 -3.466789 -5.616892 -5.099991 -2.938559 -2.337097  -6.31523   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "ZIXLT622116 -5.626789 -8.346892 -5.229991  1.031441  7.762903  14.31477   \n",
       "ZIXLT622116 -4.926789 -9.446892 -6.029991 -0.068559  8.762903  13.31477   \n",
       "ZIXLT622116 -7.626789 -6.746892 -3.529991  0.931441  9.762903  11.81477   \n",
       "ZIXLT622116 -5.326789 -8.846892 -5.229991  1.131441  8.962903  13.81477   \n",
       "ZIXLT622116 -5.126789 -7.146892 -4.429991  3.731441  8.262903  14.71477   \n",
       "\n",
       "              Month_12  Latitude  Longitude Name  \n",
       "Station_ID                                        \n",
       "ACW00011604  -2.780427   57.7667    11.8667   VE  \n",
       "ACW00011604  -3.650427   57.7667    11.8667   VE  \n",
       "ACW00011604  -3.470427   57.7667    11.8667   VE  \n",
       "ACW00011604  -1.270427   57.7667    11.8667   VE  \n",
       "ACW00011604  -4.170427   57.7667    11.8667   VE  \n",
       "...                ...       ...        ...  ...  \n",
       "ZIXLT622116  18.749573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  16.749573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  18.349573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  16.749573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  19.149573  -19.4300    29.7500  ELO  \n",
       "\n",
       "[1452682 rows x 16 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = step1_output\n",
    "df_anom = anomalize_temperature_data(df, reference_period=(1951, 1980))\n",
    "df_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec46b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
