{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16a0545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import itertools\n",
    "import math\n",
    "from io import StringIO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013b1a4",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4577507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 3rd-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add the parent folder to sys.path\n",
    "# parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Local imports\n",
    "# from parameters.data import GHCN_temp_url, GHCN_meta_url\n",
    "GHCN_temp_url = 'https://data.giss.nasa.gov/pub/gistemp/ghcnm.tavg.qcf.dat'\n",
    "GHCN_meta_url = 'https://data.giss.nasa.gov/pub/gistemp/v4.inv'\n",
    "\n",
    "def get_GHCN_data(temp_url, meta_url):\n",
    "\n",
    "    '''\n",
    "    Retrieves and formats temperature data from the Global Historical Climatology Network (GHCN) dataset.\n",
    "\n",
    "    Args:\n",
    "    temp_url (str): The URL to the temperature data file in GHCN format.\n",
    "    meta_url (str): The URL to the metadata file containing station information.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing temperature data with station metadata.\n",
    "    \n",
    "    This function sends an HTTP GET request to the temperature data URL, processes the data to create\n",
    "    a formatted DataFrame, replaces missing values with NaN, converts temperature values to degrees Celsius,\n",
    "    and merges the data with station metadata based on station IDs. The resulting DataFrame includes\n",
    "    columns for station latitude, longitude, and name, and is indexed by station IDs.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(temp_url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            \n",
    "            # Get the content of the response\n",
    "            file_data = response.content.decode(\"utf-8\")\n",
    "\n",
    "            # Create a list to store formatted data\n",
    "            formatted_data = []\n",
    "\n",
    "            # Loop through file data\n",
    "            for line in file_data.split('\\n'):\n",
    "                \n",
    "                # Check if line is not empty\n",
    "                if line.strip():\n",
    "                    \n",
    "                    # Extract relevant data\n",
    "                    # (Using code from GHCNV4Reader())\n",
    "                    station_id = line[:11]\n",
    "                    year = int(line[11:15])\n",
    "                    values = [int(line[i:i+5]) for i in range(19, 115, 8)]\n",
    "                    \n",
    "                    # Append data to list\n",
    "                    formatted_data.append([station_id, year] + values)\n",
    "\n",
    "            # Create DataFrame from formatted data\n",
    "            column_names = ['Station_ID', 'Year'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN = pd.DataFrame(formatted_data, columns=column_names)\n",
    "            \n",
    "            # Replace -9999 with NaN\n",
    "            df_GHCN.replace(-9999, np.nan, inplace=True)\n",
    "            \n",
    "            # Format data - convert to degrees C\n",
    "            month_columns = [f'Month_{i}' for i in range(1, 13)]\n",
    "            df_GHCN[month_columns] = df_GHCN[month_columns].divide(100)\n",
    "\n",
    "        else:\n",
    "            print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    # Define the column widths, create meta data dataframe\n",
    "    column_widths = [11, 9, 10, 7, 3, 31]\n",
    "    df_meta = pd.read_fwf(meta_url, widths=column_widths, header=None,\n",
    "                          names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])\n",
    "    \n",
    "    # Merge on station ID, set index\n",
    "    df = pd.merge(df_GHCN, df_meta[['Station_ID', 'Latitude', 'Longitude', 'Name']], on='Station_ID', how='left')\n",
    "    df = df.set_index('Station_ID')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def step0():\n",
    "    '''\n",
    "    Performs the initial data processing steps for the GHCN temperature dataset.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A Pandas DataFrame containing filtered and formatted temperature data.\n",
    "    \n",
    "    This function retrieves temperature data from the Global Historical Climatology Network (GHCN) dataset,\n",
    "    processes and formats the data, and returns a DataFrame. The data is first fetched using specified URLs,\n",
    "    and is returned for further analysis.\n",
    "    '''\n",
    "    df_GHCN = get_GHCN_data(GHCN_temp_url, GHCN_meta_url)\n",
    "    return df_GHCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c396e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "step0_output = step0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad6e23",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b065356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Add the parent folder to sys.path\n",
    "# parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Local imports\n",
    "# from parameters.data import drop_rules\n",
    "drop_rules = '''\n",
    "CHM00052836  omit: 0-1948\n",
    "CHXLT909860  omit: 0-1950\n",
    "BL000085365  omit: 0-1930\n",
    "MXXLT948335  omit: 0-1952\n",
    "ASN00058012  omit: 0-1899\n",
    "ASN00084016  omit: 0-1899\n",
    "ASN00069018  omit: 0-1898\n",
    "NIXLT013080  omit: 0-1930\n",
    "NIXLT751359  omit: 0-9999\n",
    "CHXLT063941  omit: 0-1937\n",
    "CHM00054843  omit: 0-1937\n",
    "MXM00076373  omit: 0-9999\n",
    "USC00044022  omit: 0-9999\n",
    "USC00044025  omit: 0-9999\n",
    "CA002402332  omit: 2011-9999\n",
    "RSM00024266  omit: 2021/09\n",
    "'''\n",
    "\n",
    "\n",
    "def filter_coordinates(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame based on latitude and longitude conditions.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame with rows where latitude is between -90 and 90,\n",
    "    and longitude is between -180 and 180.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define latitude and longitude range conditions\n",
    "    lat_condition = (df['Latitude'] >= -90) & (df['Latitude'] <= 90)\n",
    "    lon_condition = (df['Longitude'] >= -180) & (df['Longitude'] <= 180)\n",
    "\n",
    "    # Apply the conditions to filter the DataFrame\n",
    "    df_filtered = df[lat_condition & lon_condition]\n",
    "        \n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(df) - len(df_filtered)\n",
    "    print(f'Number of rows with invalid coordinates (removed): {num_filtered}')\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def filter_stations_by_rules(dataframe, rules_text):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame of climate station data based on exclusion rules specified in a text format.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing climate station data.\n",
    "        rules_text (str): A string containing exclusion rules for specific stations and years.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame with stations omitted based on the provided rules.\n",
    "\n",
    "    Rules Format:\n",
    "        The 'rules_text' should be formatted as follows:\n",
    "        - Each rule is represented as a single line in the text.\n",
    "        - Each line should start with the station ID followed by exclusion rules.\n",
    "        - Exclusion rules consist of 'omit:' followed by the years to exclude, e.g., 'omit: 2000-2010'.\n",
    "        - Years can be specified as a single year (e.g., 'omit: 2000') or as a range (e.g., 'omit: 2000-2010').\n",
    "        - Year ranges can also be specified using '/' (e.g., 'omit: 2000/2002').\n",
    "\n",
    "    Example:\n",
    "        rules_text = '''\n",
    "            CHM00052836  omit: 0-1948\n",
    "            CHXLT909860  omit: 0-1950\n",
    "            BL000085365  omit: 0-1930\n",
    "            ...\n",
    "        '''\n",
    "\n",
    "    This function takes the provided rules and applies them to the input DataFrame,\n",
    "    resulting in a new DataFrame with stations excluded based on the specified rules.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the rules from the provided text\n",
    "    rules = {}\n",
    "    for line in rules_text.split('\\n'):\n",
    "        if line.strip():\n",
    "            match = re.match(r'([A-Z0-9]+)\\s+omit:\\s+(\\S+)', line)\n",
    "            if match:\n",
    "                station_id, year_rule = match.groups()\n",
    "                rules[station_id] = year_rule\n",
    "\n",
    "    # Create a mask to identify rows to omit\n",
    "    mask = pd.Series(True, index=dataframe.index)\n",
    "\n",
    "    for station_id, year_rule in rules.items():\n",
    "        try:\n",
    "            # Split the year_rule into start and end years\n",
    "            start_year, end_year = map(int, year_rule.split('-'))\n",
    "        except ValueError:\n",
    "            # Handle cases like '2011/12' or '2012-9999'\n",
    "            if '/' in year_rule:\n",
    "                start_year = int(year_rule.split('/')[0])\n",
    "                end_year = start_year\n",
    "            elif '-' in year_rule:\n",
    "                start_year = int(year_rule.split('-')[0])\n",
    "                end_year = int(year_rule.split('-')[1])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Update the mask to False for the specified range of years for the station_id\n",
    "        mask &= ~((dataframe['Year'] >= start_year) & (dataframe['Year'] <= end_year) & (dataframe.index == station_id))\n",
    "\n",
    "    # Apply the mask to filter the DataFrame\n",
    "    filtered_dataframe = dataframe[mask]\n",
    "\n",
    "    # Calculate number of rows filtered\n",
    "    num_filtered = len(dataframe) - len(filtered_dataframe)\n",
    "    print(f'Number of rows removed according to station exclusion rules: {num_filtered}')\n",
    "\n",
    "    return filtered_dataframe\n",
    "\n",
    "\n",
    "def step1(step0_output):\n",
    "    \"\"\"\n",
    "    Applies data filtering and cleaning operations to the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        step0_output (pd.DataFrame): The initial DataFrame containing climate station data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned and filtered DataFrame ready for further analysis.\n",
    "\n",
    "    This function serves as a data processing step by applying two essential filtering operations:\n",
    "    1. `filter_coordinates`: Filters the DataFrame based on geographical coordinates, retaining relevant stations.\n",
    "    2. `filter_stations_by_rules`: Filters the DataFrame based on exclusion rules, omitting specified stations and years.\n",
    "\n",
    "    The resulting DataFrame is cleaned of irrelevant stations and years according to specified rules\n",
    "    and is ready for subsequent data analysis or visualization.\n",
    "    \"\"\"\n",
    "        \n",
    "    df_filtered = filter_coordinates(step0_output)\n",
    "    df_clean = filter_stations_by_rules(df_filtered, drop_rules)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15764ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid coordinates (removed): 0\n",
      "Number of rows removed according to station exclusion rules: 524\n"
     ]
    }
   ],
   "source": [
    "step1_output = step1(step0_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6004502",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f39fb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0e24b",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e701d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_80_cell_grid():\n",
    "    lat_bands = [-90, -64.2, -44.4, -23.6, 0, 23.6, 44.4, 64.2, 90]\n",
    "    n_bands = len(lat_bands) - 1  # Number of latitude bands\n",
    "    n_boxes_per_band = 10  # Number of boxes per band\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for band in range(n_bands):\n",
    "        lat_south = lat_bands[band]\n",
    "        lat_north = lat_bands[band + 1]\n",
    "\n",
    "        for i in range(n_boxes_per_band):\n",
    "            lon_west = -180 + i * (360 / n_boxes_per_band)\n",
    "            lon_east = -180 + (i + 1) * (360 / n_boxes_per_band)\n",
    "\n",
    "            # Calculate the equal area center latitude and longitude\n",
    "            sinc = 0.5 * (math.sin(lat_south * math.pi / 180) + math.sin(lat_north * math.pi / 180))\n",
    "            center_latitude = math.asin(sinc) * 180 / math.pi\n",
    "            center_longitude = 0.5 * (lon_west + lon_east)\n",
    "\n",
    "            data.append((lat_south, lat_north, lon_west, lon_east, center_latitude, center_longitude))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Southern', 'Northern', 'Western', 'Eastern', 'Center_Latitude', 'Center_Longitude'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def interpolate(x, y, p):\n",
    "    return y * p + (1 - p) * x\n",
    "\n",
    "# def generate_8000_cell_grid():\n",
    "#     def subgen(lat_s, lat_n, lon_w, lon_e):\n",
    "#         alts = math.sin(lat_s * math.pi / 180)\n",
    "#         altn = math.sin(lat_n * math.pi / 180)\n",
    "#         for y in range(10):\n",
    "#             s = 180 * math.asin(interpolate(alts, altn, y * 0.1)) / math.pi\n",
    "#             n = 180 * math.asin(interpolate(alts, altn, (y + 1) * 0.1)) / math.pi\n",
    "#             for x in range(10):\n",
    "#                 w = interpolate(lon_w, lon_e, x * 0.1)\n",
    "#                 e = interpolate(lon_w, lon_e, (x + 1) * 0.1)\n",
    "#                 yield (s, n, w, e)\n",
    "\n",
    "#     initial_regions_df = generate_80_cell_grid()\n",
    "#     data = []\n",
    "\n",
    "#     for index, row in initial_regions_df.iterrows():\n",
    "#         for subcell in subgen(row['Southern'], row['Northern'], row['Western'], row['Eastern']):\n",
    "#             data.append(subcell)\n",
    "\n",
    "#     grid_df = pd.DataFrame(data, columns=['Southern', 'Northern', 'Western', 'Eastern'])\n",
    "    \n",
    "#     # Calculate the center latitude and longitude\n",
    "#     grid_df['Center_Latitude'] = (grid_df['Southern'] + grid_df['Northern']) / 2\n",
    "#     grid_df['Center_Longitude'] = (grid_df['Western'] + grid_df['Eastern']) / 2\n",
    "    \n",
    "#     return grid_df\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the spherical distance (in kilometers) between two pairs of\n",
    "    latitude and longitude coordinates using the Haversine formula.\n",
    "\n",
    "    Args:\n",
    "        lat1 (float): Latitude of the first point in degrees.\n",
    "        lon1 (float): Longitude of the first point in degrees.\n",
    "        lat2 (float): Latitude of the second point in degrees.\n",
    "        lon2 (float): Longitude of the second point in degrees.\n",
    "\n",
    "    Returns:\n",
    "        float: Spherical distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    # Radius of the Earth in kilometers\n",
    "    radius = 6371.0  # Earth's mean radius\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    distance = radius * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def linearly_decreasing_weight(distance, max_distance):\n",
    "    \"\"\"\n",
    "    Calculate a linearly decreasing weight based on the given distance\n",
    "    and maximum distance.\n",
    "\n",
    "    Args:\n",
    "        distance (float): The distance at which you want to calculate the weight.\n",
    "        max_distance (float): The maximum distance at which the weight becomes 0.\n",
    "\n",
    "    Returns:\n",
    "        float: The linearly decreasing weight, ranging from 1 to 0.\n",
    "    \"\"\"\n",
    "    # Ensure that distance is within the valid range [0, max_distance]\n",
    "    distance = max(0, min(distance, max_distance))\n",
    "\n",
    "    # Calculate the weight as a linear interpolation\n",
    "    weight = 1.0 - (distance / max_distance)\n",
    "    \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a1ec21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Southern</th>\n",
       "      <th>Northern</th>\n",
       "      <th>Western</th>\n",
       "      <th>Eastern</th>\n",
       "      <th>Center_Latitude</th>\n",
       "      <th>Center_Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-90.0</td>\n",
       "      <td>-64.2</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-71.834397</td>\n",
       "      <td>-162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-90.0</td>\n",
       "      <td>-64.2</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-108.0</td>\n",
       "      <td>-71.834397</td>\n",
       "      <td>-126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-90.0</td>\n",
       "      <td>-64.2</td>\n",
       "      <td>-108.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-71.834397</td>\n",
       "      <td>-90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-90.0</td>\n",
       "      <td>-64.2</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-71.834397</td>\n",
       "      <td>-54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-90.0</td>\n",
       "      <td>-64.2</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-71.834397</td>\n",
       "      <td>-18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>64.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.834397</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>64.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>71.834397</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>64.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>71.834397</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>64.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>71.834397</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>64.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>71.834397</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Southern  Northern  Western  Eastern  Center_Latitude  Center_Longitude\n",
       "0      -90.0     -64.2   -180.0   -144.0       -71.834397            -162.0\n",
       "1      -90.0     -64.2   -144.0   -108.0       -71.834397            -126.0\n",
       "2      -90.0     -64.2   -108.0    -72.0       -71.834397             -90.0\n",
       "3      -90.0     -64.2    -72.0    -36.0       -71.834397             -54.0\n",
       "4      -90.0     -64.2    -36.0      0.0       -71.834397             -18.0\n",
       "..       ...       ...      ...      ...              ...               ...\n",
       "75      64.2      90.0      0.0     36.0        71.834397              18.0\n",
       "76      64.2      90.0     36.0     72.0        71.834397              54.0\n",
       "77      64.2      90.0     72.0    108.0        71.834397              90.0\n",
       "78      64.2      90.0    108.0    144.0        71.834397             126.0\n",
       "79      64.2      90.0    144.0    180.0        71.834397             162.0\n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_80_cell_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e48c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect meta data for stations\n",
    "GHCN_meta_url = 'https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt'\n",
    "column_widths = [11, 9, 10, 7, 3, 31]\n",
    "station_df = pd.read_fwf(GHCN_meta_url, widths=column_widths, header=None,\n",
    "                      names=['Station_ID', 'Latitude', 'Longitude', 'Elevation', 'State', 'Name'])\n",
    "\n",
    "# Create 80 cell grid\n",
    "grid_80_df = generate_80_cell_grid()\n",
    "\n",
    "# Initialize an empty list to store station IDs and weights as dictionaries\n",
    "station_weights_within_radius = []\n",
    "\n",
    "# Maximum distance for the weight calculation (e.g., 1200.0 km)\n",
    "max_distance = 1200.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a3878b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████████████████| 80/80 [00:29<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Southern  Northern  Western  Eastern  Center_Latitude  \\\n",
      "Box_Number                                                          \n",
      "0              -90.0     -64.2   -180.0   -144.0       -71.834397   \n",
      "1              -90.0     -64.2   -144.0   -108.0       -71.834397   \n",
      "2              -90.0     -64.2   -108.0    -72.0       -71.834397   \n",
      "3              -90.0     -64.2    -72.0    -36.0       -71.834397   \n",
      "4              -90.0     -64.2    -36.0      0.0       -71.834397   \n",
      "...              ...       ...      ...      ...              ...   \n",
      "75              64.2      90.0      0.0     36.0        71.834397   \n",
      "76              64.2      90.0     36.0     72.0        71.834397   \n",
      "77              64.2      90.0     72.0    108.0        71.834397   \n",
      "78              64.2      90.0    108.0    144.0        71.834397   \n",
      "79              64.2      90.0    144.0    180.0        71.834397   \n",
      "\n",
      "            Center_Longitude  \\\n",
      "Box_Number                     \n",
      "0                     -162.0   \n",
      "1                     -126.0   \n",
      "2                      -90.0   \n",
      "3                      -54.0   \n",
      "4                      -18.0   \n",
      "...                      ...   \n",
      "75                      18.0   \n",
      "76                      54.0   \n",
      "77                      90.0   \n",
      "78                     126.0   \n",
      "79                     162.0   \n",
      "\n",
      "                                              Nearby_Stations  \n",
      "Box_Number                                                     \n",
      "0           {'AYM00089327': 0.033180373720041234, 'AYM0008...  \n",
      "1           {'AYM00089324': 0.23006027330624246, 'AYM00089...  \n",
      "2           {'AYM00089062': 0.19952788531365517, 'AYM00089...  \n",
      "3           {'AYM00088963': 0.21163124644915876, 'AYM00089...  \n",
      "4           {'AYM00089001': 0.5100758876554738, 'AYM000890...  \n",
      "...                                                       ...  \n",
      "75          {'FI000002401': 0.084962737000011, 'FI00000750...  \n",
      "76          {'FI000007501': 0.03525474404660178, 'FIE00146...  \n",
      "77          {'RSM00020069': 0.23374072346639707, 'RSM00020...  \n",
      "78          {'RSM00020289': 0.13001416824544054, 'RSM00020...  \n",
      "79          {'RSM00021358': 0.5377131220987585, 'RSM000214...  \n",
      "\n",
      "[80 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tqdm to track progress\n",
    "for index, row in tqdm(grid_80_df.iterrows(), total=len(grid_80_df), desc=\"Processing\"):\n",
    "    center_lat = row['Center_Latitude']\n",
    "    center_lon = row['Center_Longitude']\n",
    "    \n",
    "    # Calculate distances for each station in station_df\n",
    "    distances = station_df.apply(lambda x: haversine_distance(center_lat, center_lon, x['Latitude'], x['Longitude']), axis=1)\n",
    "    \n",
    "    # Find station IDs within the specified radius\n",
    "    nearby_stations = station_df[distances <= max_distance]\n",
    "    \n",
    "    # Calculate weights for each nearby station\n",
    "    weights = nearby_stations.apply(lambda x: linearly_decreasing_weight(distances[x.name], max_distance), axis=1)\n",
    "    \n",
    "    # Create a dictionary of station IDs and weights\n",
    "    station_weights = dict(zip(nearby_stations['Station_ID'], weights))\n",
    "    \n",
    "    # Append the dictionary to the result list\n",
    "    station_weights_within_radius.append(station_weights)\n",
    "\n",
    "# Add the list of station IDs and weights as a new column\n",
    "grid_80_df['Nearby_Stations'] = station_weights_within_radius\n",
    "\n",
    "# Set index name\n",
    "grid_80_df.index.name = 'Box_Number'\n",
    "\n",
    "# Print grid_80_df with the new column\n",
    "print(grid_80_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bb72de8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AYM00089327': 0.033180373720041234,\n",
       " 'AYM00089345': 0.05384328602457955,\n",
       " 'AYM00089376': 0.16452351560386513,\n",
       " 'AYM00089661': 0.2129759486689381,\n",
       " 'AYM00089662': 0.07207839859029075,\n",
       " 'AYM00089664': 0.07705257354483985,\n",
       " 'AYM00089666': 0.031079631471481517,\n",
       " 'AYM00089667': 0.07063445329876195,\n",
       " 'AYM00089768': 0.05208054854286992,\n",
       " 'AYM00089769': 0.08431462499458553,\n",
       " 'AYM00089864': 0.06190969590953144,\n",
       " 'AYM00089865': 0.15713530446043067,\n",
       " 'AYM00089868': 0.040122552139423395,\n",
       " 'AYM00089872': 0.14907879375180066,\n",
       " 'AYM00089879': 0.23312986385784518,\n",
       " 'AYW00067401': 0.2404492620133053,\n",
       " 'AYW00067402': 0.4506642628052141,\n",
       " 'AYW00067601': 0.41011860537970757,\n",
       " 'AYW00068701': 0.1636133619479868,\n",
       " 'AYW00087602': 0.03229984214024895,\n",
       " 'AYW00087701': 0.21322487211259544}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_80_df['Nearby_Stations'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f259986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_box_number(station_df, grid_80_df):\n",
    "    box_numbers = []\n",
    "\n",
    "    for _, station_row in tqdm(station_df.iterrows(), total=len(station_df)):\n",
    "        latitude = station_row['Latitude']\n",
    "        longitude = station_row['Longitude']\n",
    "\n",
    "        for box_number, box_row in grid_80_df.iterrows():\n",
    "            southern = box_row['Southern']\n",
    "            northern = box_row['Northern']\n",
    "            western = box_row['Western']\n",
    "            eastern = box_row['Eastern']\n",
    "\n",
    "            if southern <= latitude <= northern and western <= longitude <= eastern:\n",
    "                box_numbers.append(box_number)\n",
    "                break\n",
    "        else:\n",
    "            box_numbers.append(None)\n",
    "\n",
    "    return box_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e896722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 124954/124954 [01:19<00:00, 1570.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find box numbers for each station, add to station_df\n",
    "box_numbers = find_box_number(station_df, grid_80_df)\n",
    "station_df['Box_Number'] = box_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b34d2e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>State</th>\n",
       "      <th>Name</th>\n",
       "      <th>Box_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>10.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DUBAI INTL</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>26.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124949</th>\n",
       "      <td>ZI000067969</td>\n",
       "      <td>-21.0500</td>\n",
       "      <td>29.3670</td>\n",
       "      <td>861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WEST NICHOLSON</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124950</th>\n",
       "      <td>ZI000067975</td>\n",
       "      <td>-20.0670</td>\n",
       "      <td>30.8670</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASVINGO</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124951</th>\n",
       "      <td>ZI000067977</td>\n",
       "      <td>-21.0170</td>\n",
       "      <td>31.5830</td>\n",
       "      <td>430.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUFFALO RANGE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124952</th>\n",
       "      <td>ZI000067983</td>\n",
       "      <td>-20.2000</td>\n",
       "      <td>32.6160</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHIPINGE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124953</th>\n",
       "      <td>ZI000067991</td>\n",
       "      <td>-22.2170</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BEITBRIDGE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124954 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Station_ID  Latitude  Longitude  Elevation State  \\\n",
       "0       ACW00011604   17.1167   -61.7833       10.1   NaN   \n",
       "1       ACW00011647   17.1333   -61.7833       19.2   NaN   \n",
       "2       AE000041196   25.3330    55.5170       34.0   NaN   \n",
       "3       AEM00041194   25.2550    55.3640       10.4   NaN   \n",
       "4       AEM00041217   24.4330    54.6510       26.8   NaN   \n",
       "...             ...       ...        ...        ...   ...   \n",
       "124949  ZI000067969  -21.0500    29.3670      861.0   NaN   \n",
       "124950  ZI000067975  -20.0670    30.8670     1095.0   NaN   \n",
       "124951  ZI000067977  -21.0170    31.5830      430.0   NaN   \n",
       "124952  ZI000067983  -20.2000    32.6160     1132.0   NaN   \n",
       "124953  ZI000067991  -22.2170    30.0000      457.0   NaN   \n",
       "\n",
       "                         Name  Box_Number  \n",
       "0       ST JOHNS COOLIDGE FLD          43  \n",
       "1                    ST JOHNS          43  \n",
       "2         SHARJAH INTER. AIRP          56  \n",
       "3                  DUBAI INTL          56  \n",
       "4              ABU DHABI INTL          56  \n",
       "...                       ...         ...  \n",
       "124949         WEST NICHOLSON          35  \n",
       "124950               MASVINGO          35  \n",
       "124951          BUFFALO RANGE          35  \n",
       "124952               CHIPINGE          35  \n",
       "124953             BEITBRIDGE          35  \n",
       "\n",
       "[124954 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851c677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d68251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d50727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35197b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf406e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75d652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfc28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77402833",
   "metadata": {},
   "source": [
    "# Step 4: SST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f19a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53979c49",
   "metadata": {},
   "source": [
    "# Step 5: Anomalyzing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8bc6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalize_temperature_data(data, reference_period=(1951, 1980)):\n",
    "    # Extract the years from the DataFrame\n",
    "    years = data['Year'].unique()\n",
    "    \n",
    "    # Calculate monthly means for the reference period\n",
    "    reference_data = data[(data['Year'] >= reference_period[0]) & (data['Year'] <= reference_period[1])]\n",
    "    monthly_means = reference_data.iloc[:, 1:13].mean()\n",
    "    \n",
    "    # Initialize a DataFrame to store the anomalized data\n",
    "    anomalized_data = data.copy()\n",
    "    \n",
    "    # Anomalize each month's data\n",
    "    for month in tqdm(range(1, 13), desc=\"Anomalizing Months\"):\n",
    "        \n",
    "        # Calculate the anomaly for the current month\n",
    "        anomalized_data[f'Month_{month}'] = data.apply(lambda row: row[f'Month_{month}'] - monthly_means[month - 1], axis=1)\n",
    "    \n",
    "    return anomalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eac5d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anomalizing Months: 100%|███████████████████████| 12/12 [00:44<00:00,  3.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1961</td>\n",
       "      <td>-1.439347</td>\n",
       "      <td>0.135949</td>\n",
       "      <td>-1.07872</td>\n",
       "      <td>-2.841062</td>\n",
       "      <td>-3.591227</td>\n",
       "      <td>-2.476789</td>\n",
       "      <td>-4.786892</td>\n",
       "      <td>-5.059991</td>\n",
       "      <td>-2.578559</td>\n",
       "      <td>-0.337097</td>\n",
       "      <td>-1.52523</td>\n",
       "      <td>-2.780427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1962</td>\n",
       "      <td>0.580653</td>\n",
       "      <td>-1.374051</td>\n",
       "      <td>-7.33872</td>\n",
       "      <td>-4.221062</td>\n",
       "      <td>-5.791227</td>\n",
       "      <td>-4.656789</td>\n",
       "      <td>-5.386892</td>\n",
       "      <td>-5.939991</td>\n",
       "      <td>-5.078559</td>\n",
       "      <td>-2.137097</td>\n",
       "      <td>-3.39523</td>\n",
       "      <td>-3.650427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1963</td>\n",
       "      <td>-7.679347</td>\n",
       "      <td>-7.754051</td>\n",
       "      <td>-6.78872</td>\n",
       "      <td>-5.161062</td>\n",
       "      <td>-2.631227</td>\n",
       "      <td>-2.196789</td>\n",
       "      <td>-4.286892</td>\n",
       "      <td>-3.909991</td>\n",
       "      <td>-3.388559</td>\n",
       "      <td>-2.677097</td>\n",
       "      <td>-0.96523</td>\n",
       "      <td>-3.470427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1964</td>\n",
       "      <td>0.070653</td>\n",
       "      <td>-3.074051</td>\n",
       "      <td>-5.24872</td>\n",
       "      <td>-3.191062</td>\n",
       "      <td>-2.681227</td>\n",
       "      <td>-4.046789</td>\n",
       "      <td>-5.426892</td>\n",
       "      <td>-4.299991</td>\n",
       "      <td>-4.498559</td>\n",
       "      <td>-4.197097</td>\n",
       "      <td>-1.16523</td>\n",
       "      <td>-1.270427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACW00011604</th>\n",
       "      <td>1965</td>\n",
       "      <td>-0.109347</td>\n",
       "      <td>-3.274051</td>\n",
       "      <td>-5.41872</td>\n",
       "      <td>-4.671062</td>\n",
       "      <td>-5.001227</td>\n",
       "      <td>-3.466789</td>\n",
       "      <td>-5.616892</td>\n",
       "      <td>-5.099991</td>\n",
       "      <td>-2.938559</td>\n",
       "      <td>-2.337097</td>\n",
       "      <td>-6.31523</td>\n",
       "      <td>-4.170427</td>\n",
       "      <td>57.7667</td>\n",
       "      <td>11.8667</td>\n",
       "      <td>VE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1966</td>\n",
       "      <td>21.290653</td>\n",
       "      <td>18.215949</td>\n",
       "      <td>12.64128</td>\n",
       "      <td>6.368938</td>\n",
       "      <td>-0.531227</td>\n",
       "      <td>-5.626789</td>\n",
       "      <td>-8.346892</td>\n",
       "      <td>-5.229991</td>\n",
       "      <td>1.031441</td>\n",
       "      <td>7.762903</td>\n",
       "      <td>14.31477</td>\n",
       "      <td>18.749573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1967</td>\n",
       "      <td>20.590653</td>\n",
       "      <td>17.715949</td>\n",
       "      <td>13.14128</td>\n",
       "      <td>8.668938</td>\n",
       "      <td>0.268773</td>\n",
       "      <td>-4.926789</td>\n",
       "      <td>-9.446892</td>\n",
       "      <td>-6.029991</td>\n",
       "      <td>-0.068559</td>\n",
       "      <td>8.762903</td>\n",
       "      <td>13.31477</td>\n",
       "      <td>16.749573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1968</td>\n",
       "      <td>21.290653</td>\n",
       "      <td>17.815949</td>\n",
       "      <td>13.54128</td>\n",
       "      <td>7.668938</td>\n",
       "      <td>0.768773</td>\n",
       "      <td>-7.626789</td>\n",
       "      <td>-6.746892</td>\n",
       "      <td>-3.529991</td>\n",
       "      <td>0.931441</td>\n",
       "      <td>9.762903</td>\n",
       "      <td>11.81477</td>\n",
       "      <td>18.349573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1969</td>\n",
       "      <td>20.390653</td>\n",
       "      <td>19.315949</td>\n",
       "      <td>13.74128</td>\n",
       "      <td>7.768938</td>\n",
       "      <td>-0.731227</td>\n",
       "      <td>-5.326789</td>\n",
       "      <td>-8.846892</td>\n",
       "      <td>-5.229991</td>\n",
       "      <td>1.131441</td>\n",
       "      <td>8.962903</td>\n",
       "      <td>13.81477</td>\n",
       "      <td>16.749573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXLT622116</th>\n",
       "      <td>1970</td>\n",
       "      <td>20.190653</td>\n",
       "      <td>17.715949</td>\n",
       "      <td>13.54128</td>\n",
       "      <td>6.668938</td>\n",
       "      <td>0.768773</td>\n",
       "      <td>-5.126789</td>\n",
       "      <td>-7.146892</td>\n",
       "      <td>-4.429991</td>\n",
       "      <td>3.731441</td>\n",
       "      <td>8.262903</td>\n",
       "      <td>14.71477</td>\n",
       "      <td>19.149573</td>\n",
       "      <td>-19.4300</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>ELO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1452682 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Year    Month_1    Month_2   Month_3   Month_4   Month_5  \\\n",
       "Station_ID                                                              \n",
       "ACW00011604  1961  -1.439347   0.135949  -1.07872 -2.841062 -3.591227   \n",
       "ACW00011604  1962   0.580653  -1.374051  -7.33872 -4.221062 -5.791227   \n",
       "ACW00011604  1963  -7.679347  -7.754051  -6.78872 -5.161062 -2.631227   \n",
       "ACW00011604  1964   0.070653  -3.074051  -5.24872 -3.191062 -2.681227   \n",
       "ACW00011604  1965  -0.109347  -3.274051  -5.41872 -4.671062 -5.001227   \n",
       "...           ...        ...        ...       ...       ...       ...   \n",
       "ZIXLT622116  1966  21.290653  18.215949  12.64128  6.368938 -0.531227   \n",
       "ZIXLT622116  1967  20.590653  17.715949  13.14128  8.668938  0.268773   \n",
       "ZIXLT622116  1968  21.290653  17.815949  13.54128  7.668938  0.768773   \n",
       "ZIXLT622116  1969  20.390653  19.315949  13.74128  7.768938 -0.731227   \n",
       "ZIXLT622116  1970  20.190653  17.715949  13.54128  6.668938  0.768773   \n",
       "\n",
       "              Month_6   Month_7   Month_8   Month_9  Month_10  Month_11  \\\n",
       "Station_ID                                                                \n",
       "ACW00011604 -2.476789 -4.786892 -5.059991 -2.578559 -0.337097  -1.52523   \n",
       "ACW00011604 -4.656789 -5.386892 -5.939991 -5.078559 -2.137097  -3.39523   \n",
       "ACW00011604 -2.196789 -4.286892 -3.909991 -3.388559 -2.677097  -0.96523   \n",
       "ACW00011604 -4.046789 -5.426892 -4.299991 -4.498559 -4.197097  -1.16523   \n",
       "ACW00011604 -3.466789 -5.616892 -5.099991 -2.938559 -2.337097  -6.31523   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "ZIXLT622116 -5.626789 -8.346892 -5.229991  1.031441  7.762903  14.31477   \n",
       "ZIXLT622116 -4.926789 -9.446892 -6.029991 -0.068559  8.762903  13.31477   \n",
       "ZIXLT622116 -7.626789 -6.746892 -3.529991  0.931441  9.762903  11.81477   \n",
       "ZIXLT622116 -5.326789 -8.846892 -5.229991  1.131441  8.962903  13.81477   \n",
       "ZIXLT622116 -5.126789 -7.146892 -4.429991  3.731441  8.262903  14.71477   \n",
       "\n",
       "              Month_12  Latitude  Longitude Name  \n",
       "Station_ID                                        \n",
       "ACW00011604  -2.780427   57.7667    11.8667   VE  \n",
       "ACW00011604  -3.650427   57.7667    11.8667   VE  \n",
       "ACW00011604  -3.470427   57.7667    11.8667   VE  \n",
       "ACW00011604  -1.270427   57.7667    11.8667   VE  \n",
       "ACW00011604  -4.170427   57.7667    11.8667   VE  \n",
       "...                ...       ...        ...  ...  \n",
       "ZIXLT622116  18.749573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  16.749573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  18.349573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  16.749573  -19.4300    29.7500  ELO  \n",
       "ZIXLT622116  19.149573  -19.4300    29.7500  ELO  \n",
       "\n",
       "[1452682 rows x 16 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = step1_output\n",
    "df_anom = anomalize_temperature_data(df, reference_period=(1951, 1980))\n",
    "df_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec46b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
